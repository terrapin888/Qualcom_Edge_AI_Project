import re
from sklearn.metrics.pairwise import cosine_similarity
import onnxruntime as ort
from transformers import AutoTokenizer
import numpy as np
import os
import torch
from datetime import datetime

#0825 ìˆ˜ì •
from services.genie_qwen import genie_analyze_intent, qwen_prompt_command, _ensure_utf8

# Nomic APIë¥¼ ì‚¬ìš©í• ì§€ ONNXë¥¼ ì‚¬ìš©í• ì§€ ì„¤ì •
USE_ONNX = True  # True: ONNX ëª¨ë¸ ì‚¬ìš©, False: Nomic API ì‚¬ìš©
ONNX_MODEL_PATH = "C:/Users/csw21/Downloads/nomic_embed_text.onnx/model.onnx/model.onnx"

# API fallbackìš©
try:
    from nomic import embed
    NOMIC_API_AVAILABLE = True
except ImportError:
    NOMIC_API_AVAILABLE = False

class ChatbotService:
    def __init__(self, config, ai_models, email_service):
        self.config = config
        self.ai_models = ai_models
        self.email_service = email_service
        
        # ONNX ëª¨ë¸ ì´ˆê¸°í™”
        self.onnx_session = None
        self.tokenizer = None
        if USE_ONNX and os.path.exists(ONNX_MODEL_PATH):
            try:
                print("[ğŸš€ ONNX] Nomic ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
                self.onnx_session = ort.InferenceSession(ONNX_MODEL_PATH)
                self.tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
                print("[âœ… ONNX] ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
            except Exception as e:
                print(f"[âŒ ONNX] ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
                print("[âš ï¸ ONNX] Nomic APIë¡œ í´ë°±í•©ë‹ˆë‹¤.")
        
        # ì±—ë´‡ ì˜ë„ ë¶„ë¥˜ìš© ë¼ë²¨ (í•œêµ­ì–´)
        self.candidate_labels = [
            "í•œêµ­ì–´ ë¬¸ë²•ê³¼ ë§ì¶¤ë²• ì˜¤ë¥˜ë¥¼ êµì •í•˜ê³  ìˆ˜ì •í•´ì£¼ì„¸ìš”",
            "í‚¤ì›Œë“œë‚˜ ì œëª©ìœ¼ë¡œ ì´ë©”ì¼ì„ ê²€ìƒ‰í•˜ê³  ì°¾ì•„ì£¼ì„¸ìš”",
            "ê¹€ì² ìˆ˜, ë°•ì˜í¬ ê°™ì€ íŠ¹ì • ì‚¬ëŒì´ ë³´ë‚¸ ì´ë©”ì¼ì„ ì°¾ì•„ì£¼ì„¸ìš”",
            "ì–´ì œ, ì˜¤ëŠ˜, ì§€ë‚œì£¼ ë“± ë‚ ì§œë¡œ ì´ë©”ì¼ì„ ê²€ìƒ‰í•´ì£¼ì„¸ìš”", 
            "ìµœì‹  ë©”ì¼ë§Œ, ì˜¤ë˜ëœ ë©”ì¼ë§Œ ë“±ìœ¼ë¡œ ì´ë©”ì¼ ëª©ë¡ì„ í•„í„°ë§í•´ì£¼ì„¸ìš”",
            "ë°›ì€ë©”ì¼í•¨ ë˜ëŠ” ë³´ë‚¸ë©”ì¼í•¨ì—ì„œë§Œ ì´ë©”ì¼ì„ ê²€ìƒ‰í•´ì£¼ì„¸ìš”",
            "ì˜¤ëŠ˜ ë©”ì¼ ê°œìˆ˜, ì´ ë©”ì¼ í†µê³„ ë“±ì„ ë³´ì—¬ì£¼ì„¸ìš”",
            "ì—¬ëŸ¬ ì¡°ê±´ì„ ì¡°í•©í•´ì„œ ë³µí•©ì ìœ¼ë¡œ ì´ë©”ì¼ì„ ê²€ìƒ‰í•´ì£¼ì„¸ìš”",
            "í°íŠ¸ í¬ê¸°, í…Œë§ˆ ëª¨ë“œ, ë°œì‹ ì ì´ë¦„, í˜ì´ì§€ë‹¹ í‘œì‹œ ê°œìˆ˜, Gmail ê°œìˆ˜ ë“± ì•± ì„¤ì •ì„ ë³€ê²½í•´ì£¼ì„¸ìš”"
        ]
        
        # í•œêµ­ì–´ íŒ¨í„´ ë§¤ì¹­
        self.korean_patterns = {
            "grammar": {
                "keywords": ["êµì •", "ë§ì¶¤ë²•", "ë¬¸ë²•", "í‹€ë ¸", "ê³ ì³", "ìˆ˜ì •"],
                "action": "grammar_correction"
            },
            "person_search": {
                "keywords": ["ë‹˜", "ì”¨"],
                "required": ["ë©”ì¼", "ì´ë©”ì¼"],
                "action": "person_search"
            },
            "general_search": {
                "keywords": ["ì°¾ì•„", "ê²€ìƒ‰", "ì°¾ê¸°"],
                "action": "email_search"
            },
            "email_stats": {
                "keywords": ["ëª‡ ê°œ", "ê°œìˆ˜", "í†µê³„", "ì–¼ë§ˆë‚˜", "ëª‡", "ì´", "í•©ê³„"],
                "action": "email_statistics"
            },
            "date_search": {
                "keywords": ["ì–´ì œ", "ì˜¤ëŠ˜", "ì§€ë‚œì£¼", "ì´ë²ˆì£¼", "ì§€ë‚œë‹¬", "ì´ë²ˆë‹¬", "ê·¸ì œ"],
                "action": "email_search",
                "detailed_intent": "search emails by date and time period"
            },
            "limit_search": {
                "keywords": ["ê°œë§Œ", "ìµœì‹ ", "ìµœê·¼"],
                "action": "email_search",
                "detailed_intent": "search emails with quantity limits"
            },
            "type_search": {
                "keywords": ["ë°›ì€ë©”ì¼", "ë³´ë‚¸ë©”ì¼"],
                "action": "email_search", 
                "detailed_intent": "search emails by type sent or received"
            },
            "settings_control": {
                "keywords": ["ì„¤ì •", "ë³€ê²½", "ë°”ê¿”", "ë°”ê¾¸", "ì¡°ì ˆ", "ìˆ˜ì •", "ì„¤ì •í•´", "ì ìš©", "ë°”ê¿”ì¤˜", "ë°”ê¿”ì£¼ì„¸ìš”", "ìœ¼ë¡œ", "í¬ê¸°ë¥¼", "í°íŠ¸"],
                "action": "settings_control",
                "detailed_intent": "change application settings"
            }
        }
    
    def process_user_input(self, user_input, user_email, app_password):
        """ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ (í•™ìŠµí˜•)"""
        try:
            import time
            start_time = time.time()
            
            print(f"\n{'='*60}")
            print(f"[ğŸ¤– ì±—ë´‡ ìš”ì²­ ì‹œì‘] ì‚¬ìš©ì: {user_email}")
            print(f"[ğŸ“ ì…ë ¥ ëª…ë ¹ì–´] '{user_input}'")
            print(f"{'='*60}")
            
            if not user_input:
                return {"error": "ì…ë ¥ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."}, 400
            
            # ğŸ¯ ìš°ì„  ì²˜ë¦¬ 1: ì„¤ì • ì…ë ¥ ëŒ€ê¸° ì¤‘ì¸ì§€ í™•ì¸
            user_input_stripped = user_input.strip()
            
            # ì„¤ì • ì…ë ¥ ëŒ€ê¸° ìƒíƒœ í™•ì¸
            try:
                import os
                awaiting_name_file = os.path.join("user_sessions", f"{user_email}_awaiting_name.txt")
                awaiting_font_file = os.path.join("user_sessions", f"{user_email}_awaiting_font.txt")
                awaiting_theme_file = os.path.join("user_sessions", f"{user_email}_awaiting_theme.txt")
                
                # ë°œì‹ ì ì´ë¦„ ëŒ€ê¸° ì¤‘
                if os.path.exists(awaiting_name_file):
                    os.remove(awaiting_name_file)  # ìƒíƒœ íŒŒì¼ ì‚­ì œ
                    print(f"[ğŸ“§ ë°œì‹ ì ì´ë¦„ ì…ë ¥ ì™„ë£Œ] '{user_input_stripped}'")
                    
                    # ë°œì‹ ì ì´ë¦„ ì„¤ì • API í˜¸ì¶œ
                    import requests
                    response = requests.put(
                        f'http://localhost:5001/api/settings/GENERAL/WRITE/senderName',
                        json={
                            'email': user_email,
                            'value': user_input_stripped
                        }
                    )
                    
                    if response.status_code == 200:
                        print(f"[âœ… ì„¤ì • ì™„ë£Œ] ë°œì‹ ì ì´ë¦„ '{user_input_stripped}'ë¡œ ì„¤ì •ë¨")
                        result_msg = f"âœ… ë°œì‹ ì ì´ë¦„ì´ '{user_input_stripped}'(ìœ¼)ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‘¤"
                    else:
                        print(f"[âŒ ì„¤ì • ì‹¤íŒ¨] API ì‘ë‹µ: {response.status_code}")
                        result_msg = f"âŒ ë°œì‹ ì ì´ë¦„ ì„¤ì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                    
                    processing_time = time.time() - start_time
                    return {
                        "response": result_msg,
                        "action": "settings_control",
                        "confidence": 0.95,
                        "processing_time": processing_time
                    }, 200
                
                
                # í°íŠ¸ ì…ë ¥ ëŒ€ê¸° ì¤‘
                elif os.path.exists(awaiting_font_file):
                    os.remove(awaiting_font_file)  # ìƒíƒœ íŒŒì¼ ì‚­ì œ
                    print(f"[ğŸ¨ í°íŠ¸ ì…ë ¥ ì™„ë£Œ] '{user_input_stripped}'")
                    
                    # í°íŠ¸ ì„¤ì • ì—…ë°ì´íŠ¸
                    from services.settings_service import SettingsService
                    settings_service = SettingsService()
                    result = settings_service.set_setting_value(
                        user_email=user_email,
                        category='GENERAL',
                        subcategory='WRITE',
                        key='fontFamily',
                        value=user_input_stripped
                    )
                    
                    if result['success']:
                        print(f"[âœ… í°íŠ¸ ì„¤ì • ì™„ë£Œ] '{user_input_stripped}'ë¡œ ì„¤ì •ë¨")
                        result_msg = f"âœ… í°íŠ¸ê°€ '{user_input_stripped}'(ìœ¼)ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ¨"
                    else:
                        print(f"[âŒ í°íŠ¸ ì„¤ì • ì‹¤íŒ¨] {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                        result_msg = f"âŒ í°íŠ¸ ì„¤ì • ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}"
                    
                    processing_time = time.time() - start_time
                    return {
                        "response": result_msg,
                        "action": "settings_control",
                        "confidence": 0.95,
                        "processing_time": processing_time
                    }, 200
                
                # í…Œë§ˆ ì…ë ¥ ëŒ€ê¸° ì¤‘
                elif os.path.exists(awaiting_theme_file):
                    os.remove(awaiting_theme_file)  # ìƒíƒœ íŒŒì¼ ì‚­ì œ
                    print(f"[ğŸŒˆ í…Œë§ˆ ì…ë ¥ ì™„ë£Œ] '{user_input_stripped}'")
                    
                    # í…Œë§ˆ ê°’ ë³€í™˜
                    theme_mapping = {
                        'ë‹¤í¬': 'dark', 'ë‹¤í¬ëª¨ë“œ': 'dark', 'ì–´ë‘¡ê²Œ': 'dark', 'ê²€ì •': 'dark',
                        'ë¼ì´íŠ¸': 'light', 'ë¼ì´íŠ¸ëª¨ë“œ': 'light', 'ë°ê²Œ': 'light', 'í°ìƒ‰': 'light',
                        'ì‹œìŠ¤í…œ': 'auto', 'ìë™': 'auto', 'ìë™ì„¤ì •': 'auto'
                    }
                    
                    theme_value = theme_mapping.get(user_input_stripped, user_input_stripped.lower())
                    if theme_value not in ['dark', 'light', 'auto']:
                        theme_value = 'light'  # ê¸°ë³¸ê°’
                    
                    # í…Œë§ˆ ì„¤ì • ì—…ë°ì´íŠ¸
                    from services.settings_service import SettingsService
                    settings_service = SettingsService()
                    result = settings_service.set_setting_value(
                        user_email=user_email,
                        category='GENERAL',
                        subcategory='THEME',
                        key='appearance',
                        value=theme_value
                    )
                    
                    if result['success']:
                        print(f"[âœ… í…Œë§ˆ ì„¤ì • ì™„ë£Œ] '{theme_value}'ë¡œ ì„¤ì •ë¨")
                        theme_name = {'dark': 'ë‹¤í¬ ëª¨ë“œ', 'light': 'ë¼ì´íŠ¸ ëª¨ë“œ', 'auto': 'ì‹œìŠ¤í…œ ì„¤ì • ë”°ë¥´ê¸°'}[theme_value]
                        result_msg = f"âœ… í…Œë§ˆê°€ '{theme_name}'(ìœ¼)ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸŒˆ"
                    else:
                        print(f"[âŒ í…Œë§ˆ ì„¤ì • ì‹¤íŒ¨] {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                        result_msg = f"âŒ í…Œë§ˆ ì„¤ì • ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}"
                    
                    processing_time = time.time() - start_time
                    return {
                        "response": result_msg,
                        "action": "settings_control",
                        "confidence": 0.95,
                        "processing_time": processing_time
                    }, 200
                    
            except Exception as e:
                print(f"[âš ï¸ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨] {e}")
            
            
            
            # ğŸ§  1ë‹¨ê³„: í•™ìŠµëœ íŒ¨í„´ì—ì„œ ì°¾ê¸°
            print(f"[ğŸ” 1ë‹¨ê³„] í•™ìŠµëœ íŒ¨í„´ì—ì„œ ë§¤ì¹­ ê²€ìƒ‰ ì‹œì‘...")
            learned_result = self._try_learned_pattern(user_email, user_input, app_password)
            if learned_result:
                processing_time = time.time() - start_time
                print(f"[âš¡ í•™ìŠµ íŒ¨í„´ ë§¤ì¹­ ì„±ê³µ!] ì²˜ë¦¬ì‹œê°„: {processing_time:.3f}ì´ˆ (ë¹ ë¦„!)")
                print(f"[âœ… í•™ìŠµ ì‹œìŠ¤í…œ íš¨ê³¼] AI ì²˜ë¦¬ ì—†ì´ ë°”ë¡œ ì‹¤í–‰ë¨")
                print(f"{'='*60}\n")
                return {
                    **learned_result,
                    "method": "learned_pattern",
                    "processing_time": processing_time
                }, 200
            
            # ğŸ” 2ë‹¨ê³„: Qwen ê¸°ë°˜ Intent ë¶„ë¥˜
            print(f"[âŒ 1ë‹¨ê³„ ê²°ê³¼] í•™ìŠµëœ íŒ¨í„´ ì—†ìŒ - Qwen Intent ë¶„ë¥˜ë¡œ ì§„í–‰")
            print(f"[ğŸ§  2ë‹¨ê³„] Qwen ê¸°ë°˜ ì˜ë„ ë¶„ë¥˜ ì‹œì‘...")
            
            # Qwen ê¸°ë°˜ ì˜ë„ ë¶„ë¥˜ (ì •í™•í•¨)
            intent_result = self._classify_intent_with_qwen(user_input)
            
            # Qwen ì‹¤íŒ¨ ì‹œ Nomic í´ë°±
            if not intent_result:
                print(f"[âš ï¸ Qwen ì‹¤íŒ¨] Nomic í´ë°±ìœ¼ë¡œ ì „í™˜")
                intent_result = self._analyze_intent(user_input)
            
            print(f"[ğŸ¯ ì˜ë„ ë¶„ì„ ê²°ê³¼] {intent_result['action']} (ì‹ ë¢°ë„: {intent_result['confidence']:.3f})")
            print(f"[ğŸ”§ ë¶„ì„ ë°©ë²•] {intent_result['method']}")
            
            # ê¸°ëŠ¥ë³„ ì‹¤í–‰ (ì„¸ë¶„í™”ëœ ì˜ë„ ì²˜ë¦¬)
            print(f"[âš™ï¸ ê¸°ëŠ¥ ì‹¤í–‰] {intent_result['action']} í•¸ë“¤ëŸ¬ í˜¸ì¶œ ì¤‘...")
            print(f"[ğŸ“‹ ì„¸ë¶€ ì˜ë„] {intent_result.get('detailed_intent', 'general')}")
            
            if intent_result['action'] == "grammar_correction":
                response = self._handle_grammar_correction(user_input)
            elif intent_result['action'] == "email_search":
                # ì„¸ë¶„í™”ëœ ê²€ìƒ‰ ì˜ë„ì— ë”°ë¼ ë‹¤ë¥¸ ì²˜ë¦¬
                detailed_intent = intent_result.get('detailed_intent', '')
                
                if "date and time period" in detailed_intent:
                    response = self._handle_date_search(user_input, user_email, app_password)
                elif "quantity limits" in detailed_intent:
                    response = self._handle_limit_search(user_input, user_email, app_password)
                elif "type sent or received" in detailed_intent:
                    response = self._handle_type_search(user_input, user_email, app_password)
                elif "multiple conditions" in detailed_intent:
                    response = self._handle_complex_search(user_input, user_email, app_password)
                else:
                    response = self._handle_general_search(user_input, user_email, app_password)
            elif intent_result['action'] == "person_search":
                response = self._handle_person_search(user_input, user_email, app_password)
            elif intent_result['action'] == "email_statistics":
                response = self._handle_email_statistics(user_input, user_email, app_password)
            elif intent_result['action'] == "settings_control":
                response = self._handle_settings_control(user_input, user_email, intent_result.get('details', ''))
            else:
                response = self._handle_unknown_intent()
            
            # ğŸ”¥ 3ë‹¨ê³„: AI ì²˜ë¦¬ ì„±ê³µ ì‹œ í•™ìŠµ ì €ì¥ (ì˜¤ë¥˜ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ)
            processing_time = time.time() - start_time
            
            # ì‘ë‹µì´ ì„±ê³µì ì´ê³  ì˜¤ë¥˜ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ ì €ì¥
            if response and not isinstance(response, dict) or (isinstance(response, dict) and not response.get('error')):
                print(f"[ğŸ’¾ 3ë‹¨ê³„] ì„±ê³µì ì¸ ì‘ë‹µ - í•™ìŠµ ë°ì´í„° ì €ì¥ ì‹œì‘...")
                
                # ì €ì¥í•  ì‘ë‹µ ë°ì´í„° ì¤€ë¹„
                save_response = response
                if isinstance(response, dict) and 'results' in response:
                    # ê²€ìƒ‰ ê²°ê³¼ì¸ ê²½ìš° ê°„ë‹¨í•œ ìš”ì•½ë§Œ ì €ì¥
                    save_response = f"ê²€ìƒ‰ ì™„ë£Œ: {len(response.get('results', []))}ê°œ ê²°ê³¼"
                
                self._auto_save_learned_command(user_email, user_input, intent_result, save_response)
            else:
                print(f"[âš ï¸ 3ë‹¨ê³„] ì‘ë‹µì— ì˜¤ë¥˜ ìˆìŒ - í•™ìŠµ ë°ì´í„° ì €ì¥ ìƒëµ")
            
            print(f"[â±ï¸ ì´ ì²˜ë¦¬ì‹œê°„] {processing_time:.3f}ì´ˆ (AI ì²˜ë¦¬ í¬í•¨)")
            print(f"[ğŸ“š ë‹¤ìŒ ì‹¤í–‰] ë™ì¼/ìœ ì‚¬ ëª…ë ¹ì–´ëŠ” {processing_time:.3f}ì´ˆ â†’ 0.05ì´ˆë¡œ ë‹¨ì¶•ë¨")
            print(f"{'='*60}\n")
            
            return {
                "response": response,
                "action": intent_result['action'],
                "confidence": float(intent_result['confidence']),
                "detected_intent": intent_result['action'],
                "detection_method": intent_result['method'],
                "method": "ai_processing",
                "processing_time": processing_time
            }, 200
            
        except Exception as e:
            print(f"[â—ì±—ë´‡ ì˜¤ë¥˜] {str(e)}")
            return {"error": str(e)}, 500
    
    def _get_embeddings(self, texts):
        """í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± (ONNX ìš°ì„ , API í´ë°±)"""
        if self.onnx_session and self.tokenizer:
            # ONNX ëª¨ë¸ ì‚¬ìš©
            try:
                print(f"[ğŸš€ ì±—ë´‡ ONNX] ì„ë² ë”© ìƒì„± ì‹œì‘ - {len(texts)}ê°œ í…ìŠ¤íŠ¸")
                embeddings = []
                for i, text in enumerate(texts):
                    inputs = self.tokenizer(
                        text, 
                        padding="max_length", 
                        max_length=128, 
                        truncation=True,
                        return_tensors="np"
                    )
                    
                    outputs = self.onnx_session.run(None, {
                        "input_tokens": inputs["input_ids"].astype(np.int32),
                        "attention_masks": inputs["attention_mask"].astype(np.float32)
                    })
                    embeddings.append(outputs[0][0])  # ì²« ë²ˆì§¸ ì¶œë ¥ì˜ ì²« ë²ˆì§¸ ë²¡í„°
                    print(f"[âœ… ì±—ë´‡ ONNX] í…ìŠ¤íŠ¸ {i+1}/{len(texts)} ì„ë² ë”© ì™„ë£Œ")
                
                print(f"[ğŸ‰ ì±—ë´‡ ONNX] ì „ì²´ ì„ë² ë”© ìƒì„± ì™„ë£Œ!")
                return {'embeddings': embeddings}
            except Exception as e:
                print(f"[âš ï¸ ONNX] ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
                # APIë¡œ í´ë°±
        
        # Nomic API ì‚¬ìš©
        if NOMIC_API_AVAILABLE:
            from nomic import embed
            return embed.text(texts, model='nomic-embed-text-v1', task_type='classification')
        else:
            raise Exception("ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    def _qwen_analyze_intent(self, user_input):
        """Qwen ê¸°ë°˜ ì •í™•í•œ ì˜ë„ ë¶„ì„"""
        try:
            # Qwen ëª¨ë¸ ë¡œë”© í™•ì¸
            if not self.ai_models.load_qwen_model():
                print("[âš ï¸ Qwen ëª¨ë¸ ì—†ìŒ - ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±]")
                return self._analyze_intent(user_input)
            
            print(f"[ğŸ¤– Qwen ì˜ë„ ë¶„ì„] ì…ë ¥: '{user_input}'")
            
            # ê°„ë‹¨í•˜ê³  íš¨ê³¼ì ì¸ Qwen í”„ë¡¬í”„íŠ¸
            prompt = f"""ëª…ë ¹ì–´: "{user_input}"

ì˜ë„ ë¶„ë¥˜:
1. grammar_correction: ë¬¸ë²•/ë§ì¶¤ë²• êµì •
2. email_search: ì´ë©”ì¼ ê²€ìƒ‰
3. person_search: íŠ¹ì • ì‚¬ëŒ ë©”ì¼ ì°¾ê¸°
4. settings_control: ì„¤ì • ë³€ê²½

ì˜ˆì‹œ:
"í°íŠ¸ 18ë¡œ ë°”ê¿”ì¤˜" â†’ settings_control, font_size_18
"ë‹¤í¬ëª¨ë“œë¡œ" â†’ settings_control, theme_dark
"ê¹€ì² ìˆ˜ë‹˜ ë©”ì¼" â†’ person_search, ê¹€ì² ìˆ˜
"ë©”ì¼ ê²€ìƒ‰" â†’ email_search, general

ì‘ë‹µ í˜•ì‹: action, keyword

ë¶„ì„:"""

            # Qwen ì‹¤í–‰
            inputs = self.ai_models.qwen_tokenizer(prompt, return_tensors="pt", max_length=512, truncation=True).to(self.ai_models.qwen_model.device)
            
            with torch.no_grad():
                outputs = self.ai_models.qwen_model.generate(
                    inputs.input_ids,
                    max_new_tokens=150,
                    temperature=0.1,  # ë‚®ì€ ì˜¨ë„ë¡œ ì¼ê´€ì„± í™•ë³´
                    do_sample=True,
                    eos_token_id=self.ai_models.qwen_tokenizer.eos_token_id,
                    pad_token_id=self.ai_models.qwen_tokenizer.pad_token_id
                )
            
            generated_text = self.ai_models.qwen_tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            print(f"[ğŸ” ë””ë²„ê·¸] ì „ì²´ ìƒì„±ëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(generated_text)}")
            print(f"[ğŸ” ë””ë²„ê·¸] í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)}")
            print(f"[ğŸ” ë””ë²„ê·¸] ì „ì²´ ìƒì„± í…ìŠ¤íŠ¸ ì¼ë¶€: {generated_text[:200]}...")
            
            # í”„ë¡¬í”„íŠ¸ ë¶€ë¶„ ì œê±°í•˜ê³  ì‘ë‹µë§Œ ì¶”ì¶œ
            if "ë¶„ì„:" in generated_text:
                qwen_response = generated_text.split("ë¶„ì„:")[-1].strip()
                print(f"[ğŸ” ë””ë²„ê·¸] 'ë¶„ì„:' ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬")
            else:
                qwen_response = generated_text[len(prompt):].strip()
                print(f"[ğŸ” ë””ë²„ê·¸] í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬")
            
            print(f"[ğŸ¤– Qwen ì›ë³¸ ì‘ë‹µ] {qwen_response}")
            
            # ìƒˆë¡œìš´ ë‹¨ìˆœ í˜•ì‹ íŒŒì‹±: "action, keyword"
            import re
            
            # "action, keyword" í˜•ì‹ íŒŒì‹±
            if qwen_response:
                # ì²« ë²ˆì§¸ ì¤„ë§Œ ì‚¬ìš© (ì—¬ëŸ¬ ì¤„ì¼ ìˆ˜ ìˆìŒ)
                first_line = qwen_response.split('\n')[0].strip()
                
                # "action, keyword" í˜•ì‹ìœ¼ë¡œ íŒŒì‹±
                if ',' in first_line:
                    parts = first_line.split(',', 1)
                    if len(parts) >= 2:
                        action = parts[0].strip()
                        keyword = parts[1].strip()
                        
                        print(f"[âœ… Qwen íŒŒì‹± ì„±ê³µ] action='{action}', keyword='{keyword}'")
                        
                        return {
                            'action': action,
                            'confidence': 0.9,
                            'method': 'qwen_ai_simple',
                            'detailed_intent': keyword,
                            'qwen_raw': qwen_response
                        }
            
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„
            print(f"[ğŸ”„ Qwen í´ë°±] ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨, í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„ìœ¼ë¡œ ì „í™˜")
            return self._parse_qwen_response_fallback(user_input, qwen_response)
            
        except Exception as e:
            print(f"[â— Qwen ì˜ë„ ë¶„ì„ ì˜¤ë¥˜] {str(e)}")
            # ì˜¤ë¥˜ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
            return self._analyze_intent(user_input)
    
    

    def _parse_qwen_response_fallback(self, user_input, qwen_response):
        """Qwen ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨ ì‹œ í´ë°± ë¶„ì„"""
        user_lower = user_input.lower()
        response_lower = qwen_response.lower()
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ì˜ë„ ê²°ì •
        if any(word in user_lower for word in ["ë°›ì€ë©”ì¼ë§Œ", "ë°›ì€ë©”ì¼", "ë°›ì€í¸ì§€í•¨"]) and "ê²€ìƒ‰" in user_lower:
            return {'action': 'type_search', 'confidence': 0.8, 'method': 'qwen_fallback', 'detailed_intent': 'received_only'}
        elif any(word in user_lower for word in ["ë³´ë‚¸ë©”ì¼ë§Œ", "ë³´ë‚¸ë©”ì¼", "ë³´ë‚¸í¸ì§€í•¨"]) and "ê²€ìƒ‰" in user_lower:
            return {'action': 'type_search', 'confidence': 0.8, 'method': 'qwen_fallback', 'detailed_intent': 'sent_only'}
        elif "ë‹˜" in user_lower or "ì”¨" in user_lower:
            return {'action': 'person_search', 'confidence': 0.8, 'method': 'qwen_fallback', 'detailed_intent': 'person'}
        elif re.search(r'\d+ê°œ', user_lower) or "ìµœì‹ " in user_lower:
            return {'action': 'limit_search', 'confidence': 0.8, 'method': 'qwen_fallback', 'detailed_intent': 'limit'}
        elif any(word in user_lower for word in ["ì–´ì œ", "ì˜¤ëŠ˜", "ì§€ë‚œì£¼", "ì´ë²ˆì£¼"]):
            return {'action': 'date_search', 'confidence': 0.8, 'method': 'qwen_fallback', 'detailed_intent': 'date'}
        elif any(word in user_lower for word in ["êµì •", "ë§ì¶¤ë²•", "ë¬¸ë²•"]):
            return {'action': 'grammar_correction', 'confidence': 0.8, 'method': 'qwen_fallback', 'detailed_intent': 'grammar'}
        elif any(word in user_lower for word in ["ê°œìˆ˜", "í†µê³„", "ëª‡ê°œ"]):
            return {'action': 'email_statistics', 'confidence': 0.8, 'method': 'qwen_fallback', 'detailed_intent': 'stats'}
        elif any(word in user_lower for word in ["í°íŠ¸", "ê¸€ê¼´", "í¬ê¸°", "ê¸€ì"]) and any(word in user_lower for word in ["ë°”ê¿”", "ë°”ê¿”ì¤˜", "ì„¤ì •", "ë³€ê²½", "ìœ¼ë¡œ"]):
            return {'action': 'settings_control', 'confidence': 0.85, 'method': 'qwen_fallback', 'detailed_intent': 'font_settings'}
        elif any(word in user_lower for word in ["ë‹¤í¬ëª¨ë“œ", "ë¼ì´íŠ¸ëª¨ë“œ", "í…Œë§ˆ"]) and any(word in user_lower for word in ["ë°”ê¿”", "ë°”ê¿”ì¤˜", "ì„¤ì •", "ë³€ê²½"]):
            return {'action': 'settings_control', 'confidence': 0.85, 'method': 'qwen_fallback', 'detailed_intent': 'theme_settings'}
        else:
            return {'action': 'email_search', 'confidence': 0.7, 'method': 'qwen_fallback', 'detailed_intent': 'general'}

    def _qwen_analyze_intent(self, user_input):
        """Qwenì„ ì‚¬ìš©í•œ ì •í™•í•œ ì˜ë„ ë¶„ë¥˜ (ë©”ì¸)"""
        try:
            if not self.ai_models.load_qwen_model():
                print("[âš ï¸ Qwen ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ - Nomicìœ¼ë¡œ í´ë°±]")
                return None
            
            prompt = f"""ë‹¹ì‹ ì€ ì´ë©”ì¼ í´ë¼ì´ì–¸íŠ¸ì˜ ì±—ë´‡ì…ë‹ˆë‹¤. ì‚¬ìš©ì ì…ë ¥ì˜ ì˜ë„ë¥¼ ì •í™•íˆ ë¶„ë¥˜í•˜ì„¸ìš”.

ê°€ëŠ¥í•œ ì˜ë„:
1. grammar_correction - ë§ì¶¤ë²•/ë¬¸ë²• êµì • ìš”ì²­
2. email_search - í‚¤ì›Œë“œë¡œ ì´ë©”ì¼ ê²€ìƒ‰
3. person_search - íŠ¹ì • ì‚¬ëŒì˜ ì´ë©”ì¼ ì°¾ê¸°
4. email_statistics - ì´ë©”ì¼ í†µê³„ ì¡°íšŒ
5. settings_control - ì•± ì„¤ì • ë³€ê²½ (í°íŠ¸, í…Œë§ˆ, í˜ì´ì§€, ë°œì‹ ì ì´ë¦„ ë“±)
6. date_search - ë‚ ì§œë³„ ì´ë©”ì¼ ê²€ìƒ‰
7. type_search - ë°›ì€ë©”ì¼/ë³´ë‚¸ë©”ì¼ ê²€ìƒ‰
8. limit_search - ê°œìˆ˜ ì œí•œ ê²€ìƒ‰

ì‚¬ìš©ì ì…ë ¥: "{user_input}"

ì˜ë„ë¥¼ í•œ ë‹¨ì–´ë¡œë§Œ ë‹µí•˜ì„¸ìš” (ì˜ˆ: settings_control):"""
            
            # Qwen ì‹¤í–‰
            inputs = self.ai_models.qwen_tokenizer(prompt, return_tensors="pt", max_length=512, truncation=True).to(self.ai_models.qwen_model.device)
            
            with torch.no_grad():
                outputs = self.ai_models.qwen_model.generate(
                    inputs.input_ids,
                    max_new_tokens=50,
                    temperature=0.1,
                    do_sample=True,
                    eos_token_id=self.ai_models.qwen_tokenizer.eos_token_id,
                    pad_token_id=self.ai_models.qwen_tokenizer.pad_token_id
                )
            
            generated_text = self.ai_models.qwen_tokenizer.decode(outputs[0], skip_special_tokens=True)
            response = generated_text[len(prompt):].strip()
            intent = response.strip().lower()
            
            # ìœ íš¨í•œ ì˜ë„ì¸ì§€ í™•ì¸
            valid_intents = ['grammar_correction', 'email_search', 'person_search', 
                           'email_statistics', 'settings_control', 'date_search',
                           'type_search', 'limit_search']
            
            if intent in valid_intents:
                print(f"[âœ… Qwen ì˜ë„ ë¶„ë¥˜] {intent} (ì‹ ë¢°ë„: ë†’ìŒ)")
                return {'action': intent, 'confidence': 0.95, 'method': 'qwen_main'}
            else:
                print(f"[âš ï¸ Qwen ì• ë§¤í•œ ì‘ë‹µ] {intent}")
                return None
                
        except Exception as e:
            print(f"[âŒ Qwen ì˜ë„ ë¶„ë¥˜ ì˜¤ë¥˜] {str(e)}")
            return None
    
    def _analyze_intent(self, user_input):
        """ì˜ë„ ë¶„ì„ (Qwen ìš°ì„ , Nomic í´ë°±)"""
        
        # 1. Qwenìœ¼ë¡œ ì˜ë„ ë¶„ì„ (ë©”ì¸)
        qwen_result = self._qwen_analyze_intent(user_input)
        if qwen_result and qwen_result['confidence'] >= 0.9:
            return qwen_result
        
        # 2. Qwenì´ ì• ë§¤í•˜ë©´ Nomic ì„ë² ë”©ìœ¼ë¡œ ë³´ì¡°
        # ì˜ì–´ Embedding ê¸°ë°˜ ë¶„ë¥˜
        try:
            text_inputs = [user_input] + self.candidate_labels
            result = self._get_embeddings(text_inputs)
            
            embedding_list = result['embeddings']
            email_embedding = [embedding_list[0]]
            label_embeddings = embedding_list[1:]
            
            scores = cosine_similarity(email_embedding, label_embeddings)[0]
            best_index = scores.argmax()
            embedding_score = scores[best_index]
            embedding_label = self.candidate_labels[best_index]
            
        except Exception as e:
            print(f"[âš ï¸ Embedding ë¶„ë¥˜ ì‹¤íŒ¨] {str(e)}")
            embedding_score = 0.0
            embedding_label = "unknown"
        
        # 3. í•œêµ­ì–´ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜
        korean_result = self._analyze_korean_patterns(user_input)
        
        # 3. ìµœì¢… ì˜ë„ ê²°ì •
        embedding_action_map = {
            "í•œêµ­ì–´ ë¬¸ë²•ê³¼ ë§ì¶¤ë²• ì˜¤ë¥˜ë¥¼ êµì •í•˜ê³  ìˆ˜ì •í•´ì£¼ì„¸ìš”": "grammar_correction",
            "í‚¤ì›Œë“œë‚˜ ì œëª©ìœ¼ë¡œ ì´ë©”ì¼ì„ ê²€ìƒ‰í•˜ê³  ì°¾ì•„ì£¼ì„¸ìš”": "email_search",
            "ê¹€ì² ìˆ˜, ë°•ì˜í¬ ê°™ì€ íŠ¹ì • ì‚¬ëŒì´ ë³´ë‚¸ ì´ë©”ì¼ì„ ì°¾ì•„ì£¼ì„¸ìš”": "person_search",
            "ì–´ì œ, ì˜¤ëŠ˜, ì§€ë‚œì£¼ ë“± ë‚ ì§œë¡œ ì´ë©”ì¼ì„ ê²€ìƒ‰í•´ì£¼ì„¸ìš”": "email_search", 
            "ìµœì‹  ë©”ì¼ë§Œ, ì˜¤ë˜ëœ ë©”ì¼ë§Œ ë“±ìœ¼ë¡œ ì´ë©”ì¼ ëª©ë¡ì„ í•„í„°ë§í•´ì£¼ì„¸ìš”": "email_search",
            "ë°›ì€ë©”ì¼í•¨ ë˜ëŠ” ë³´ë‚¸ë©”ì¼í•¨ì—ì„œë§Œ ì´ë©”ì¼ì„ ê²€ìƒ‰í•´ì£¼ì„¸ìš”": "email_search",
            "ì˜¤ëŠ˜ ë©”ì¼ ê°œìˆ˜, ì´ ë©”ì¼ í†µê³„ ë“±ì„ ë³´ì—¬ì£¼ì„¸ìš”": "email_statistics",
            "ì—¬ëŸ¬ ì¡°ê±´ì„ ì¡°í•©í•´ì„œ ë³µí•©ì ìœ¼ë¡œ ì´ë©”ì¼ì„ ê²€ìƒ‰í•´ì£¼ì„¸ìš”": "email_search",
            "í°íŠ¸ í¬ê¸°, í…Œë§ˆ ëª¨ë“œ, ë°œì‹ ì ì´ë¦„, í˜ì´ì§€ë‹¹ í‘œì‹œ ê°œìˆ˜, Gmail ê°œìˆ˜ ë“± ì•± ì„¤ì •ì„ ë³€ê²½í•´ì£¼ì„¸ìš”": "settings_control"
        }
        
        embedding_action = embedding_action_map.get(embedding_label, "unknown")
        embedding_threshold = 0.25
        
        # 4. ìµœì¢… ì˜ë„ ê²°ì • (Qwen ê²°ê³¼ ìš°ì„ )
        # Qwen ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
        if qwen_result:
            # Nomicì´ë‚˜ í•œêµ­ì–´ íŒ¨í„´ìœ¼ë¡œ ë³´ì™„
            if embedding_score >= 0.7 and embedding_action == qwen_result['action']:
                # Qwenê³¼ Nomicì´ ì¼ì¹˜í•˜ë©´ ì‹ ë¢°ë„ ìƒìŠ¹
                qwen_result['confidence'] = min(0.99, qwen_result['confidence'] + 0.1)
                print(f"[ğŸ¯ ì˜ë„ ì¼ì¹˜] Qwenê³¼ Nomic ì¼ì¹˜ - ì‹ ë¢°ë„ ìƒìŠ¹")
            return qwen_result
        
        # Qwenì´ ì‹¤íŒ¨í–ˆì„ ë•Œ ê¸°ì¡´ ë¡œì§
        if korean_result["confidence"] >= 0.3 and korean_result["confidence"] > embedding_score:
            return {
                'action': korean_result["action"],
                'confidence': korean_result["confidence"],
                'method': 'korean_pattern',
                'detailed_intent': korean_result.get('detailed_intent', '')
            }
        elif embedding_score >= embedding_threshold:
            return {
                'action': embedding_action,
                'confidence': embedding_score,
                'method': 'nomic_fallback',
                'detailed_intent': embedding_label
            }
        else:
            # ëª¨ë“  ë°©ë²•ì´ ì‹¤íŒ¨í•˜ë©´ Qwen í´ë°± ì‚¬ìš©
            return self._qwen_fallback_analyze(user_input)
    
    def _analyze_korean_patterns(self, user_input):
        """í•œêµ­ì–´ íŒ¨í„´ ë¶„ì„"""
        user_input_lower = user_input.lower()
        
        korean_result = {"action": None, "confidence": 0.0, "matched_keywords": []}
        
        # ìˆ«ì íŒ¨í„´ ì²´í¬ (ì˜ˆ: "5ê°œ", "10ê°œë§Œ")
        import re
        has_number_limit = bool(re.search(r'\d+ê°œ', user_input_lower))
        
        for pattern_name, pattern_info in self.korean_patterns.items():
            matched_keywords = []
            
            # ì¼ë°˜ í‚¤ì›Œë“œ ë§¤ì¹­
            for keyword in pattern_info["keywords"]:
                if keyword in user_input_lower:
                    matched_keywords.append(keyword)
            
            # í•„ìˆ˜ í‚¤ì›Œë“œ í™•ì¸ (person_searchìš©)
            if "required" in pattern_info:
                required_found = any(req in user_input_lower for req in pattern_info["required"])
                if not required_found:
                    continue
            
            # ì‹ ë¢°ë„ ê³„ì‚°
            if matched_keywords:
                confidence = len(matched_keywords) / len(pattern_info["keywords"])
                
                # person_searchëŠ” íŠ¹ë³„ ì²˜ë¦¬
                if pattern_name == "person_search" and "required" in pattern_info:
                    confidence += 0.3
                
                # limit_searchëŠ” ìˆ«ì íŒ¨í„´ì´ ìˆìœ¼ë©´ ì‹ ë¢°ë„ ì¦ê°€
                if pattern_name == "limit_search" and has_number_limit:
                    confidence += 0.5
                    matched_keywords.append("ìˆ«ìê°œìˆ˜")
                
                # settings_controlëŠ” íŠ¹ë³„ ì²˜ë¦¬ (í°íŠ¸/í…Œë§ˆ/ì„¤ì • ê´€ë ¨ í‚¤ì›Œë“œ ì¡°í•©)
                if pattern_name == "settings_control":
                    # ì„¤ì • ê´€ë ¨ í‚¤ì›Œë“œ ì •ì˜
                    font_keywords = ["í°íŠ¸", "ê¸€ê¼´", "í¬ê¸°", "ê¸€ì", "px", "í¬ì¸íŠ¸"]
                    theme_keywords = ["í…Œë§ˆ", "ë‹¤í¬ëª¨ë“œ", "ë¼ì´íŠ¸ëª¨ë“œ", "ì–´ë‘ìš´", "ë°ì€"]
                    sender_keywords = ["ì´ë¦„", "ë°œì‹ ì", "ë³´ë‚´ëŠ”", "ì‚¬ëŒ", "sender"]
                    gmail_keywords = ["gmail", "ë©”ì¼", "ê°œìˆ˜", "ê°€ì ¸ì˜¤", "fetch"]
                    page_keywords = ["í˜ì´ì§€", "ëª©ë¡", "ë¦¬ìŠ¤íŠ¸", "ë³´ì—¬", "í‘œì‹œ", "ê°œì”©", "ì”©", "í•œ í˜ì´ì§€"]
                    action_keywords = ["ë°”ê¿”", "ë°”ê¿”ì¤˜", "ë°”ê¿”ì£¼ì„¸ìš”", "ë³€ê²½", "ì„¤ì •", "ì¡°ì ˆ", "ìœ¼ë¡œ", "ì„¤ì •í•´", "ì„¤ì •í•´ì¤˜", "í•´ì¤˜"]
                    
                    has_font = any(kw in user_input_lower for kw in font_keywords)
                    has_theme = any(kw in user_input_lower for kw in theme_keywords)
                    has_sender = any(kw in user_input_lower for kw in sender_keywords)
                    has_gmail = any(kw in user_input_lower for kw in gmail_keywords)
                    has_page = any(kw in user_input_lower for kw in page_keywords)
                    has_action = any(kw in user_input_lower for kw in action_keywords)
                    
                    # í™•ì‹¤í•œ ì„¤ì • ë³€ê²½ íŒ¨í„´ë“¤
                    if (has_font or has_theme or has_sender or has_gmail or has_page) and has_action:
                        confidence = 0.95  # ë§¤ìš° ë†’ì€ ì‹ ë¢°ë„ë¡œ ì„¤ì •
                        matched_keywords.extend(["í™•ì‹¤í•œ_ì„¤ì •_ë³€ê²½"])
                        setting_type = ""
                        if has_font: setting_type = "í°íŠ¸"
                        elif has_theme: setting_type = "í…Œë§ˆ"
                        elif has_sender: setting_type = "ë°œì‹ ì"
                        elif has_gmail: setting_type = "Gmail"
                        elif has_page: setting_type = "í˜ì´ì§€"
                        print(f"[ğŸ¯ ì„¤ì • ê°•í™”] {setting_type}+ì•¡ì…˜ ì¡°í•© ê°ì§€ â†’ ì‹ ë¢°ë„ 0.95")
                    elif has_action and len(matched_keywords) >= 2:
                        confidence += 0.4  # ì•¡ì…˜ í‚¤ì›Œë“œ + ë‹¤ìˆ˜ ë§¤ì¹­ì‹œ ì‹ ë¢°ë„ ì¦ê°€
                        print(f"[ğŸ¯ ì„¤ì • ê°•í™”] ì•¡ì…˜+ë³µìˆ˜í‚¤ì›Œë“œ ì¡°í•© â†’ ì‹ ë¢°ë„ +0.4")
                
                if confidence > korean_result["confidence"]:
                    korean_result = {
                        "action": pattern_info["action"],
                        "confidence": confidence,
                        "matched_keywords": matched_keywords,
                        "detailed_intent": pattern_info.get("detailed_intent", "")
                    }
        
        return korean_result
    
    def _handle_grammar_correction(self, user_input):
        """ë¬¸ë²• êµì • ì²˜ë¦¬"""
        try:
            # Qwenìœ¼ë¡œ êµì •í•  í…ìŠ¤íŠ¸ ì •í™• ì¶”ì¶œ
            correction_text = self._extract_grammar_text_with_qwen(user_input)
            
            if not correction_text:
                return "ğŸ“ **ë¬¸ë²• ë° ë§ì¶¤ë²• êµì •**\n\nêµì •í•˜ê³  ì‹¶ì€ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\n\nì˜ˆì‹œ: 'ì•ˆë…•í•˜ì„¸ìš”. ì œê°€ ì˜¤ëŠ˜ íšŒì˜ì— ì°¸ì„ëª»í• ê²ƒ ê°™ìŠµë‹ˆë‹¤' êµì •í•´ì£¼ì„¸ìš”"
            
            # Qwen ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©
            if self.ai_models.load_qwen_model():
                try:
                    prompt = f"""<|im_start|>system
ë‹¹ì‹ ì€ ì „ë¬¸ êµì • í¸ì§‘ìì…ë‹ˆë‹¤.
<|im_end|>
<|im_start|>user
ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ë§ì¶¤ë²•, ë¬¸ë²•, ë„ì–´ì“°ê¸°ë¥¼ êµì •í•´ì£¼ì„¸ìš”.

ì›ë³¸ í…ìŠ¤íŠ¸:
"{correction_text}"

êµì • ì§€ì¹¨:
1. ë§ì¶¤ë²• ì˜¤ë¥˜ ìˆ˜ì •
2. ë¬¸ë²• ì˜¤ë¥˜ ìˆ˜ì •  
3. ë„ì–´ì“°ê¸° ìˆ˜ì •
4. ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ìœ¼ë¡œ ê°œì„ 
5. ì›ë˜ ì˜ë¯¸ëŠ” ìœ ì§€

êµì •ëœ í…ìŠ¤íŠ¸:
<|im_end|>
<|im_start|>assistant
"""
                    
                    inputs = self.ai_models.qwen_tokenizer(prompt, return_tensors="pt").to(self.ai_models.qwen_model.device)
                    
                    import torch
                    with torch.no_grad():
                        outputs = self.ai_models.qwen_model.generate(
                            **inputs,
                            max_new_tokens=200,
                            temperature=0.3,
                            do_sample=True,
                            top_p=0.9,
                            eos_token_id=self.ai_models.qwen_tokenizer.eos_token_id,
                            pad_token_id=self.ai_models.qwen_tokenizer.pad_token_id
                        )
                    
                    generated_text = self.ai_models.qwen_tokenizer.decode(outputs[0], skip_special_tokens=True)
                    
                    if "assistant" in generated_text:
                        corrected_text = generated_text.split("assistant")[-1].strip()
                    else:
                        corrected_text = generated_text[len(prompt):].strip()
                    
                    return f"""ğŸ“ **ë¬¸ë²• ë° ë§ì¶¤ë²• êµì • ì™„ë£Œ**

**ì›ë³¸:**
{correction_text}

**êµì •ëœ í…ìŠ¤íŠ¸:**
{corrected_text}

âœ… **AI êµì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!**"""
                    
                except Exception as e:
                    print(f"[âš ï¸ Qwen ë¬¸ë²• êµì • ì‹¤íŒ¨] {str(e)}")
                    return self._simple_grammar_correction(correction_text)
            else:
                # Qwen ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ ì‹œ ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ êµì •
                return self._simple_grammar_correction(correction_text)
                
        except Exception as e:
            return "âŒ ë¬¸ë²• êµì • ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def _simple_grammar_correction(self, text):
        """ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ êµì •"""
        simple_corrections = {
            "ë°ì´íƒ€": "ë°ì´í„°", "ì»´í“¨íƒ€": "ì»´í“¨í„°", "ì…‹íŒ…": "ì„¤ì •",
            "ë¯¸íŒ…": "íšŒì˜", "í•´ì•¼ë˜ëŠ”": "í•´ì•¼ í•˜ëŠ”", "í• ìˆ˜ìˆëŠ”": "í•  ìˆ˜ ìˆëŠ”",
            "ëª»í• ê²ƒ": "ëª»í•  ê²ƒ", "ì°¸ì„ëª»í• ": "ì°¸ì„í•˜ì§€ ëª»í• "
        }
        
        corrected_simple = text
        applied_corrections = []
        
        for wrong, correct in simple_corrections.items():
            if wrong in corrected_simple:
                corrected_simple = corrected_simple.replace(wrong, correct)
                applied_corrections.append(f"'{wrong}' â†’ '{correct}'")
        
        if applied_corrections:
            return f"""ğŸ“ **ê°„ë‹¨ ë§ì¶¤ë²• êµì •**

**ì›ë³¸:** {text}
**êµì •ëœ í…ìŠ¤íŠ¸:** {corrected_simple}

**ì ìš©ëœ êµì •:**
{chr(10).join('â€¢ ' + correction for correction in applied_corrections)}"""
        else:
            return f"ğŸ“ **êµì • ê²€í†  ì™„ë£Œ**\n\ní˜„ì¬ í…ìŠ¤íŠ¸ì—ì„œ ëª…ë°±í•œ ì˜¤ë¥˜ë¥¼ ë°œê²¬í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
    
    
    def _translate_korean_to_english(self, text):
        """í•œêµ­ì–´ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­"""
        korean_to_english = {
            "ê³ ì–‘ì´": "cute cat", "ê°•ì•„ì§€": "cute dog", "ê½ƒ": "beautiful flowers",
            "ë°”ë‹¤": "ocean and waves", "ì‚°": "mountains and nature", "ì„ì–‘": "beautiful sunset",
            "í•˜ëŠ˜": "blue sky with clouds", "ìˆ²": "forest and trees", "ë„ì‹œ": "modern city",
            "ìë™ì°¨": "modern car", "ì§‘": "beautiful house", "ì‚¬ëŒ": "person"
        }
        
        english_text = text
        for korean, english in korean_to_english.items():
            if korean in text:
                english_text = english_text.replace(korean, english)
        
        # í•œêµ­ì–´ê°€ ë‚¨ì•„ìˆìœ¼ë©´ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ìƒì„±
        if any(ord(char) > 127 for char in english_text):
            english_text = f"a beautiful {text}"
        
        return english_text
    
    def _handle_general_search(self, user_input, user_email, app_password):
        """ì¼ë°˜ ì´ë©”ì¼ ê²€ìƒ‰ (ê³ ê¸‰ ê¸°ëŠ¥ í¬í•¨)"""
        try:
            print(f"[ğŸ” ê³ ê¸‰ ê²€ìƒ‰ ì‹œì‘] ì…ë ¥: '{user_input}'")
            
            # Qwenìœ¼ë¡œ ë‚ ì§œ, ê°œìˆ˜ ì œí•œ íŒŒì‹±
            qwen_date = self._extract_date_with_qwen(user_input)
            date_filter = self._convert_date_type_to_filter(qwen_date) if qwen_date else None
            
            qwen_limit = self._extract_limit_with_qwen(user_input)
            limit_count = qwen_limit
            mail_type_filter = self._parse_mail_type_keywords(user_input)
            
            # ê²€ìƒ‰ í‚¤ì›Œë“œ ì¶”ì¶œ (íŒŒì‹±ëœ í‚¤ì›Œë“œë“¤ ì œê±°)
            # Qwenìœ¼ë¡œ ê²€ìƒ‰ í‚¤ì›Œë“œ ì •í™• ì¶”ì¶œ
            search_keywords = self._extract_keyword_with_qwen(user_input)
            
            if not search_keywords:
                # í´ë°±: ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì¶”ì¶œ
                search_keywords = user_input.lower()
                remove_words = [
                    "ì°¾ì•„ì¤˜", "ì°¾ì•„ì£¼ì„¸ìš”", "ê²€ìƒ‰í•´ì¤˜", "ê²€ìƒ‰", "find", "search", "ë©”ì¼", "ì´ë©”ì¼", "email",
                    "ì˜¤ëŠ˜", "ì–´ì œ", "ì´ë²ˆì£¼", "ì´ë²ˆ ì£¼", "ì§€ë‚œì£¼", "ì´ë²ˆë‹¬", "ì´ë²ˆ ë‹¬", "ì§€ë‚œë‹¬",
                    "today", "yesterday", "this week", "last week", "this month", "last month",
                    "ë°›ì€", "ë³´ë‚¸", "ë°›ì€ë©”ì¼", "ë³´ë‚¸ë©”ì¼", "ìˆ˜ì‹ ", "ë°œì‹ ", "inbox", "sent",
                    "ê°œë§Œ", "ê°œê¹Œì§€", "ìµœê·¼", "ìµœì‹ ", "ì²˜ìŒ", "ìƒìœ„"
                ]
                import re
                search_keywords = re.sub(r'\d+\s*ê°œ\s*(ë§Œ|ê¹Œì§€)*', '', search_keywords)
                search_keywords = re.sub(r'ìµœê·¼\s*\d+\s*ì¼', '', search_keywords)
                for word in remove_words:
                    search_keywords = search_keywords.replace(word, "").strip()
                print(f"[âš ï¸ í´ë°±] ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì¶”ì¶œëœ í‚¤ì›Œë“œ: '{search_keywords}'")
            
            # ë‚¨ì€ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì•ˆë‚´
            if not search_keywords and not date_filter and not mail_type_filter:
                return "ğŸ” **ë©”ì¼ ê²€ìƒ‰**\n\nê²€ìƒ‰í•˜ê³  ì‹¶ì€ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\n\nğŸ’¡ **ê³ ê¸‰ ê²€ìƒ‰ ì˜ˆì‹œ:**\nâ€¢ 'íšŒì˜ ê´€ë ¨ ë©”ì¼ ì°¾ì•„ì¤˜'\nâ€¢ 'ì–´ì œ ë°›ì€ ë©”ì¼ ë³´ì—¬ì¤˜'\nâ€¢ 'ê¹€ì² ìˆ˜ë‹˜ ì§€ë‚œì£¼ ë©”ì¼'\nâ€¢ 'ìµœê·¼ 5ê°œ ë©”ì¼ë§Œ'\nâ€¢ 'ë°›ì€ë©”ì¼ë§Œ ê²€ìƒ‰'"
            
            # í‚¤ì›Œë“œê°€ ì—†ì–´ë„ ë‚ ì§œ/íƒ€ì… í•„í„°ê°€ ìˆìœ¼ë©´ ê²€ìƒ‰ ì§„í–‰
            if not search_keywords:
                search_keywords = ""  # ë¹ˆ ë¬¸ìì—´ë¡œ ëª¨ë“  ë©”ì¼ ê²€ìƒ‰
            
            print(f"[ğŸ¯ ìµœì¢… ê²€ìƒ‰ í‚¤ì›Œë“œ] '{search_keywords}'")
            
            # âœ… DBì—ì„œ ì´ë©”ì¼ ê²€ìƒ‰ ì‹¤í–‰ (ê³ ê¸‰ ì˜µì…˜ í¬í•¨)
            try:
                found_emails = self._search_emails_in_db(
                    user_email, 
                    search_keywords, 
                    max_results=50,
                    date_filter=date_filter,
                    mail_type_filter=mail_type_filter,
                    limit_count=limit_count
                )
                
                if found_emails:
                    # ê²€ìƒ‰ ì¡°ê±´ ì •ë³´ ìƒì„±
                    search_info = []
                    
                    if search_keywords:
                        search_info.append(f"í‚¤ì›Œë“œ: '{search_keywords}'")
                    
                    if date_filter:
                        date_type = date_filter.get('type', 'unknown')
                        if date_type == 'today':
                            search_info.append("ë‚ ì§œ: ì˜¤ëŠ˜")
                        elif date_type == 'yesterday':
                            search_info.append("ë‚ ì§œ: ì–´ì œ")
                        elif date_type == 'this_week':
                            search_info.append("ë‚ ì§œ: ì´ë²ˆì£¼")
                        elif date_type == 'last_week':
                            search_info.append("ë‚ ì§œ: ì§€ë‚œì£¼")
                        elif date_type == 'this_month':
                            search_info.append("ë‚ ì§œ: ì´ë²ˆë‹¬")
                        elif date_type == 'last_month':
                            search_info.append("ë‚ ì§œ: ì§€ë‚œë‹¬")
                        elif 'recent_' in date_type and '_days' in date_type:
                            days = date_type.split('_')[1]
                            search_info.append(f"ë‚ ì§œ: ìµœê·¼ {days}ì¼")
                    
                    if mail_type_filter:
                        type_name = "ë°›ì€ë©”ì¼" if mail_type_filter == 'inbox' else "ë³´ë‚¸ë©”ì¼"
                        search_info.append(f"íƒ€ì…: {type_name}")
                    
                    if limit_count:
                        search_info.append(f"ê°œìˆ˜: {limit_count}ê°œ ì œí•œ")
                    
                    search_condition = " | ".join(search_info) if search_info else "ì „ì²´ ê²€ìƒ‰"
                    
                    result = f"ğŸ” **ê³ ê¸‰ ê²€ìƒ‰ ê²°ê³¼**\n\nğŸ“‹ **ê²€ìƒ‰ ì¡°ê±´**: {search_condition}\nğŸ“§ **ì°¾ì€ ë©”ì¼**: **{len(found_emails)}ê°œ**\n\n"
                    
                    for i, mail_info in enumerate(found_emails[:5], 1):  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                        result += f"**ğŸ“¬ {i}ë²ˆì§¸ ë©”ì¼**\n"
                        result += f"ğŸ“‹ **ì œëª©**: {mail_info['subject']}\n"
                        result += f"ğŸ‘¤ **ë°œì‹ ì**: {mail_info['from']}\n"
                        result += f"ğŸ“… **ë‚ ì§œ**: {mail_info['date']}\n"
                        
                        # ìš”ì•½ì´ ìˆìœ¼ë©´ í‘œì‹œ
                        if mail_info.get('summary') and mail_info['summary'] != 'ìš”ì•½ ì—†ìŒ':
                            result += f"ğŸ“ **ìš”ì•½**: {mail_info['summary']}\n"
                        elif mail_info['preview']:
                            result += f"ğŸ’¬ **ë¯¸ë¦¬ë³´ê¸°**: {mail_info['preview'][:100]}{'...' if len(mail_info['preview']) > 100 else ''}\n"
                        
                        # ë¶„ë¥˜ê°€ ìˆìœ¼ë©´ í‘œì‹œ
                        if mail_info.get('classification') and mail_info['classification'] != 'unknown':
                            result += f"ğŸ·ï¸ **ë¶„ë¥˜**: {mail_info['classification']}\n"
                        
                        result += "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                    
                    if len(found_emails) > 5:
                        result += f"ğŸ“Š **ë” ìˆìŒ**: ì´ {len(found_emails)}ê°œ ì¤‘ ìƒìœ„ 5ê°œë§Œ í‘œì‹œ\n"
                    
                    result += "\nğŸ’¡ ë” ì •í™•í•œ ê²€ìƒ‰ì„ ìœ„í•´ êµ¬ì²´ì ì¸ í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”."
                    return result
                else:
                    return f"ğŸ” **ê²€ìƒ‰ ê²°ê³¼**\n\ní‚¤ì›Œë“œ: '{search_keywords}'\n\nâŒ ê´€ë ¨ëœ ë©”ì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\nğŸ’¡ **ê²€ìƒ‰ íŒ**:\nâ€¢ ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„\nâ€¢ ë°œì‹ ì ì´ë¦„ì´ë‚˜ ì´ë©”ì¼ ì£¼ì†Œë¡œ ê²€ìƒ‰\nâ€¢ ë©”ì¼ ì œëª©ì˜ ì¼ë¶€ë¡œ ê²€ìƒ‰"
                    
            except Exception as e:
                return f"âŒ ë©”ì¼ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\nì˜¤ë¥˜: {str(e)}"
                
        except Exception as e:
            return "âŒ ê²€ìƒ‰ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def _handle_person_search(self, user_input, user_email, app_password):
        """íŠ¹ì • ì‚¬ëŒ ë©”ì¼ ê²€ìƒ‰"""
        try:
            # Qwenìœ¼ë¡œ ì‚¬ëŒ ì´ë¦„/ì´ë©”ì¼ ì •í™• ì¶”ì¶œ
            extract_type, search_target = self._extract_person_or_email_with_qwen(user_input)
            
            if not search_target or len(search_target.strip()) < 2:
                # ê°„ë‹¨í•œ ì¶”ì¶œ ë°©ë²•
                words = user_input.split()
                potential_targets = []
                
                for word in words:
                    if "@" in word and "." in word:  # ì´ë©”ì¼ ì£¼ì†Œ
                        potential_targets.append(word)
                    elif len(word) >= 2 and len(word) <= 4 and word.replace(" ", "").isalpha():  # í•œêµ­ì–´ ì´ë¦„
                        potential_targets.append(word)
                
                if potential_targets:
                    search_target = potential_targets[0]
                else:
                    return "ğŸ‘¤ **ì‚¬ëŒë³„ ë©”ì¼ ê²€ìƒ‰**\n\nì°¾ê³  ì‹¶ì€ ì‚¬ëŒì˜ ì´ë¦„ì´ë‚˜ ì´ë©”ì¼ ì£¼ì†Œë¥¼ ëª…í™•íˆ ì•Œë ¤ì£¼ì„¸ìš”.\n\nì˜ˆì‹œ:\nâ€¢ 'ê¹€ì² ìˆ˜ë‹˜ì˜ ë©”ì¼'\nâ€¢ 'john@company.com ë©”ì¼'"
            
            try:
                # Qwenìœ¼ë¡œ ê³ ê¸‰ ê²€ìƒ‰ ì˜µì…˜ íŒŒì‹±
                qwen_date = self._extract_date_with_qwen(user_input)
                date_filter = self._convert_date_type_to_filter(qwen_date) if qwen_date else None
                
                qwen_limit = self._extract_limit_with_qwen(user_input)
                limit_count = qwen_limit
                mail_type_filter = self._parse_mail_type_keywords(user_input)
                
                print(f"[ğŸ” ì‚¬ëŒë³„ ê³ ê¸‰ ê²€ìƒ‰] íƒ€ì…: {extract_type}, ëŒ€ìƒ: '{search_target}'")
                
                # âœ… DBì—ì„œ ì‚¬ëŒë³„ ì´ë©”ì¼ ê²€ìƒ‰ ì‹¤í–‰ (ê³ ê¸‰ ì˜µì…˜ í¬í•¨)
                found_emails = self._search_emails_in_db(
                    user_email, 
                    search_target, 
                    max_results=100,
                    date_filter=date_filter,
                    mail_type_filter=mail_type_filter,
                    limit_count=limit_count
                )
                
                # ë°œì‹ ì ì •ë³´ë¡œ í•„í„°ë§
                person_emails = []
                search_lower = search_target.lower()
                
                for email_info in found_emails:
                    from_field = email_info['from'].lower()
                    if (search_lower in from_field or 
                        any(part.strip() in from_field for part in search_lower.split() if part.strip())):
                        person_emails.append(email_info)
                        
                        if len(person_emails) >= 10:
                            break
                
                if person_emails:
                    result = f"ğŸ‘¤ **ì‚¬ëŒë³„ ë©”ì¼ ê²€ìƒ‰ ê²°ê³¼**\n\nğŸ¯ ê²€ìƒ‰ ëŒ€ìƒ: **{search_target}**\nğŸ“§ ë°œê²¬ëœ ë©”ì¼: **{len(person_emails)}ê°œ**\n\n"
                    
                    for i, mail_info in enumerate(person_emails[:5], 1):  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                        result += f"**ğŸ“¬ {i}ë²ˆì§¸ ë©”ì¼**\n"
                        result += f"ğŸ“‹ **ì œëª©**: {mail_info['subject']}\n"
                        result += f"ğŸ‘¤ **ë°œì‹ ì**: {mail_info['from']}\n"
                        result += f"ğŸ“… **ë‚ ì§œ**: {mail_info['date']}\n"
                        
                        # ìš”ì•½ì´ ìˆìœ¼ë©´ í‘œì‹œ
                        if mail_info.get('summary') and mail_info['summary'] != 'ìš”ì•½ ì—†ìŒ':
                            result += f"ğŸ“ **ìš”ì•½**: {mail_info['summary']}\n"
                        elif mail_info['preview']:
                            result += f"ğŸ’¬ **ë¯¸ë¦¬ë³´ê¸°**: {mail_info['preview'][:100]}{'...' if len(mail_info['preview']) > 100 else ''}\n"
                        
                        # ë¶„ë¥˜ê°€ ìˆìœ¼ë©´ í‘œì‹œ
                        if mail_info.get('classification') and mail_info['classification'] != 'unknown':
                            result += f"ğŸ·ï¸ **ë¶„ë¥˜**: {mail_info['classification']}\n"
                        
                        result += "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                    
                    if len(person_emails) > 5:
                        result += f"ğŸ“Š **ë” ìˆìŒ**: ì´ {len(person_emails)}ê°œ ì¤‘ ìƒìœ„ 5ê°œë§Œ í‘œì‹œ\n"
                    
                    result += "\nğŸ’¡ íŠ¹ì • ë©”ì¼ì„ ìì„¸íˆ ë³´ë ¤ë©´ ë©”ì¼ ë¦¬ìŠ¤íŠ¸ì—ì„œ í™•ì¸í•˜ì„¸ìš”."
                    return result
                else:
                    return f"ğŸ‘¤ **ì‚¬ëŒë³„ ë©”ì¼ ê²€ìƒ‰ ê²°ê³¼**\n\nğŸ¯ ê²€ìƒ‰ ëŒ€ìƒ: **{search_target}**\n\nâŒ í•´ë‹¹ ì‚¬ëŒì˜ ë©”ì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\nğŸ’¡ **ê²€ìƒ‰ íŒ**:\nâ€¢ ì •í™•í•œ ì´ë¦„ì´ë‚˜ ì´ë©”ì¼ ì£¼ì†Œë¡œ ì¬ì‹œë„\nâ€¢ ì´ë©”ì¼ ì£¼ì†Œ ì „ì²´ ì…ë ¥\nâ€¢ í•œê¸€ ì´ë¦„ì˜ ê²½ìš° ì„±í•¨ìœ¼ë¡œë§Œ ê²€ìƒ‰"
                    
            except Exception as e:
                return f"âŒ ì‚¬ëŒë³„ ë©”ì¼ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\nì˜¤ë¥˜: {str(e)}"
                
        except Exception as e:
            return "âŒ ì‚¬ëŒ ê²€ìƒ‰ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def _extract_person_or_email_with_qwen(self, user_input):
        """Qwenì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ëŒ ì´ë¦„ì´ë‚˜ ì´ë©”ì¼ ì£¼ì†Œë¥¼ ì •í™•íˆ ì¶”ì¶œ"""
        try:
            print(f"[ğŸ¤– Qwen ì¶”ì¶œ ì‹œì‘] ì‚¬ëŒ/ì´ë©”ì¼ ì¶”ì¶œ: '{user_input}'")
            
            # Qwen ëª¨ë¸ ë¡œë”©
            if not hasattr(self.ai_models, 'qwen_model') or self.ai_models.qwen_model is None:
                print("[ğŸ¤– Qwen ëª¨ë¸ ë¡œë”© ì‹œì‘]")
                self.ai_models.load_qwen_model()
            
            prompt = f"""í•œêµ­ì–´ ëª…ë ¹ì—ì„œ ì‚¬ëŒ ì´ë¦„ì´ë‚˜ ì´ë©”ì¼ ì£¼ì†Œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.
í˜•ì‹: type|ê°’

íƒ€ì…:
- person: ì‚¬ëŒ ì´ë¦„ (ê¹€ì² ìˆ˜, ë°•ì˜í¬, êµìˆ˜ë‹˜ ë“±)
- email: ì´ë©”ì¼ ì£¼ì†Œ (@í¬í•¨)

ì˜ˆì‹œ:
"ìµœìˆ˜ìš´ ì´ë©”ì¼ ì°¾ì•„ì¤˜" â†’ person|ìµœìˆ˜ìš´
"ê¹€ì² ìˆ˜ë‹˜ ë©”ì¼ ë³´ì—¬ì¤˜" â†’ person|ê¹€ì² ìˆ˜
"abc@gmail.comì—ì„œ ì˜¨ ë©”ì¼" â†’ email|abc@gmail.com
"êµìˆ˜ë‹˜ ë©”ì¼" â†’ person|êµìˆ˜ë‹˜
"Johnì˜ ë©”ì¼" â†’ person|John
"íŒ€ì¥ë‹˜ ì´ë©”ì¼" â†’ person|íŒ€ì¥

ì…ë ¥: "{user_input}"
ê²°ê³¼:"""
            
            # í† í°í™”
            inputs = self.ai_models.qwen_tokenizer(prompt, return_tensors="pt")
            
            # ìƒì„±
            import torch
            with torch.no_grad():
                outputs = self.ai_models.qwen_model.generate(
                    inputs.input_ids,
                    max_new_tokens=20,  # ì§§ì€ ì‘ë‹µë§Œ í•„ìš”
                    do_sample=False,
                    temperature=0.1,
                    eos_token_id=self.ai_models.qwen_tokenizer.eos_token_id,
                    pad_token_id=self.ai_models.qwen_tokenizer.pad_token_id
                )
            
            generated_text = self.ai_models.qwen_tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            # ì‘ë‹µ ì¶”ì¶œ
            if "ê²°ê³¼:" in generated_text:
                qwen_response = generated_text.split("ê²°ê³¼:")[-1].strip()
            else:
                qwen_response = generated_text[len(prompt):].strip()
            
            print(f"[ğŸ¤– Qwen ì‘ë‹µ] {qwen_response}")
            
            # ì‘ë‹µ íŒŒì‹±: "type|value" í˜•ì‹
            lines = qwen_response.strip().split('\n')
            for line in lines:
                line = line.strip()
                if '|' in line and not line.startswith('-'):
                    parts = line.split('|', 1)
                    if len(parts) == 2:
                        extract_type = parts[0].strip()
                        extract_value = parts[1].strip()
                        
                        # ìœ íš¨í•œ íƒ€ì…ì¸ì§€ í™•ì¸
                        if extract_type in ['person', 'email']:
                            print(f"[âœ… ì¶”ì¶œ ì„±ê³µ] {extract_type} = '{extract_value}'")
                            return extract_type, extract_value
            
            print(f"[âŒ ì¶”ì¶œ ì‹¤íŒ¨] íŒŒì‹±í•  ìˆ˜ ì—†ëŠ” ì‘ë‹µ: '{qwen_response}'")
            return None, None
            
        except Exception as e:
            print(f"[â— Qwen ì¶”ì¶œ ì˜¤ë¥˜] {str(e)}")
            return None, None

    def _extract_grammar_text_with_qwen(self, user_input):
        """Qwenì„ ì‚¬ìš©í•˜ì—¬ êµì •í•  í…ìŠ¤íŠ¸ë§Œ ì •í™•íˆ ì¶”ì¶œ"""
        try:
            print(f"[ğŸ¤– Qwen êµì • í…ìŠ¤íŠ¸ ì¶”ì¶œ] '{user_input}'")
            
            # Qwen ëª¨ë¸ ë¡œë”©
            if not hasattr(self.ai_models, 'qwen_model') or self.ai_models.qwen_model is None:
                print("[ğŸ¤– Qwen ëª¨ë¸ ë¡œë”© ì‹œì‘]")
                self.ai_models.load_qwen_model()
            
            prompt = f"""í•œêµ­ì–´ ëª…ë ¹ì—ì„œ êµì •í•  í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.
í˜•ì‹: text|êµì •í• í…ìŠ¤íŠ¸

ê·œì¹™:
- êµì •í•´ì¤˜, ë§ì¶¤ë²•, ë¬¸ë²• ë“±ì˜ ëª…ë ¹ì–´ëŠ” ì œê±°
- ì‹¤ì œ êµì •ì´ í•„ìš”í•œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ

ì˜ˆì‹œ:
"ì•ˆë…•í•˜ì„¸ìš”. ì œê°€ ì˜¤ëŠ˜ íšŒì˜ì— ì°¸ì„ëª»í• ê²ƒ ê°™ìŠµë‹ˆë‹¤ êµì •í•´ì£¼ì„¸ìš”" â†’ text|ì•ˆë…•í•˜ì„¸ìš”. ì œê°€ ì˜¤ëŠ˜ íšŒì˜ì— ì°¸ì„ëª»í• ê²ƒ ê°™ìŠµë‹ˆë‹¤
"'I can't attend meeting today' êµì •í•´ì¤˜" â†’ text|I can't attend meeting today
"ë§ì¶¤ë²• ê²€ì‚¬: ì•ˆë…•í•˜ìƒˆìš”" â†’ text|ì•ˆë…•í•˜ìƒˆìš”
"ë¬¸ë²• ì²´í¬í•´ì¤˜ ì˜¤ëŠ˜ ì €ë…ì— ë­ ë¨¹ì„ê¹Œìš”" â†’ text|ì˜¤ëŠ˜ ì €ë…ì— ë­ ë¨¹ì„ê¹Œìš”

ì…ë ¥: "{user_input}"
ê²°ê³¼:"""
            
            # í† í°í™”
            inputs = self.ai_models.qwen_tokenizer(prompt, return_tensors="pt")
            
            # ìƒì„±
            import torch
            with torch.no_grad():
                outputs = self.ai_models.qwen_model.generate(
                    inputs.input_ids,
                    max_new_tokens=100,  # êµì •í•  í…ìŠ¤íŠ¸ëŠ” ê¸¸ ìˆ˜ ìˆìŒ
                    do_sample=False,
                    temperature=0.1,
                    eos_token_id=self.ai_models.qwen_tokenizer.eos_token_id,
                    pad_token_id=self.ai_models.qwen_tokenizer.pad_token_id
                )
            
            generated_text = self.ai_models.qwen_tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            # ì‘ë‹µ ì¶”ì¶œ
            if "ê²°ê³¼:" in generated_text:
                qwen_response = generated_text.split("ê²°ê³¼:")[-1].strip()
            else:
                qwen_response = generated_text[len(prompt):].strip()
            
            print(f"[ğŸ¤– Qwen ì‘ë‹µ] {qwen_response}")
            
            # ì‘ë‹µ íŒŒì‹±: "text|value" í˜•ì‹
            lines = qwen_response.strip().split('\n')
            for line in lines:
                line = line.strip()
                if '|' in line and line.startswith('text|'):
                    parts = line.split('|', 1)
                    if len(parts) == 2:
                        extracted_text = parts[1].strip()
                        # ë”°ì˜´í‘œ ì œê±°
                        if extracted_text.startswith('"') and extracted_text.endswith('"'):
                            extracted_text = extracted_text[1:-1]
                        if extracted_text.startswith("'") and extracted_text.endswith("'"):
                            extracted_text = extracted_text[1:-1]
                        
                        print(f"[âœ… êµì • í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ] '{extracted_text}'")
                        return extracted_text
            
            print(f"[âŒ êµì • í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨] íŒŒì‹±í•  ìˆ˜ ì—†ëŠ” ì‘ë‹µ: '{qwen_response}'")
            return None
            
        except Exception as e:
            print(f"[â— Qwen êµì • í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜] {str(e)}")
            return None

    def _extract_keyword_with_qwen(self, user_input):
        """Qwenì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ í‚¤ì›Œë“œë§Œ ì •í™•íˆ ì¶”ì¶œ"""
        try:
            print(f"[ğŸ¤– Qwen í‚¤ì›Œë“œ ì¶”ì¶œ] '{user_input}'")
            
            # Qwen ëª¨ë¸ ë¡œë”©
            if not hasattr(self.ai_models, 'qwen_model') or self.ai_models.qwen_model is None:
                print("[ğŸ¤– Qwen ëª¨ë¸ ë¡œë”© ì‹œì‘]")
                self.ai_models.load_qwen_model()
            
            prompt = f"""í•œêµ­ì–´ ëª…ë ¹ì—ì„œ ê²€ìƒ‰ í‚¤ì›Œë“œë§Œ ì¶”ì¶œí•˜ì„¸ìš”.
í˜•ì‹: keyword|ì¶”ì¶œëœí‚¤ì›Œë“œ

ê·œì¹™:
- ë©”ì¼, ì´ë©”ì¼, ì°¾ì•„ì¤˜, ê²€ìƒ‰, ë³´ì—¬ì¤˜ëŠ” ë°˜ë“œì‹œ ì œê±°
- í•µì‹¬ ê²€ìƒ‰ì–´ë§Œ ë‚¨ê¸°ê¸°
- ì˜ì–´ ë‹¨ì–´ë„ ê·¸ëŒ€ë¡œ ìœ ì§€

ì˜ˆì‹œ:
"íšŒì˜ ê´€ë ¨ ë©”ì¼ ê²€ìƒ‰í•´ì¤˜" â†’ keyword|íšŒì˜ ê´€ë ¨
"ngrok ì´ë©”ì¼ì„ ì°¾ì•„ì¤˜" â†’ keyword|ngrok
"notion team ì´ë©”ì¼ì„ ì°¾ì•„ì¤˜" â†’ keyword|notion team  
"zoom ê´€ë ¨ ë©”ì¼" â†’ keyword|zoom
"í”„ë¡œì íŠ¸ ì—…ë°ì´íŠ¸ ì°¾ì•„ì¤˜" â†’ keyword|í”„ë¡œì íŠ¸ ì—…ë°ì´íŠ¸
"ChatGPT ë©”ì¼ ë³´ì—¬ì¤˜" â†’ keyword|ChatGPT

ì…ë ¥: "{user_input}"
ê²°ê³¼:"""
            
            # í† í°í™”
            inputs = self.ai_models.qwen_tokenizer(prompt, return_tensors="pt")
            
            # ìƒì„±
            import torch
            with torch.no_grad():
                outputs = self.ai_models.qwen_model.generate(
                    inputs.input_ids,
                    max_new_tokens=30,  # í‚¤ì›Œë“œëŠ” ì§§ìŒ
                    do_sample=False,
                    temperature=0.1,
                    eos_token_id=self.ai_models.qwen_tokenizer.eos_token_id,
                    pad_token_id=self.ai_models.qwen_tokenizer.pad_token_id
                )
            
            generated_text = self.ai_models.qwen_tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            # ì‘ë‹µ ì¶”ì¶œ
            if "ê²°ê³¼:" in generated_text:
                qwen_response = generated_text.split("ê²°ê³¼:")[-1].strip()
            else:
                qwen_response = generated_text[len(prompt):].strip()
            
            print(f"[ğŸ¤– Qwen ì‘ë‹µ] {qwen_response}")
            
            # ì‘ë‹µ íŒŒì‹±: "keyword|value" í˜•ì‹
            lines = qwen_response.strip().split('\n')
            for line in lines:
                line = line.strip()
                if '|' in line and line.startswith('keyword|'):
                    parts = line.split('|', 1)
                    if len(parts) == 2:
                        extracted_keyword = parts[1].strip()
                        print(f"[âœ… í‚¤ì›Œë“œ ì¶”ì¶œ ì„±ê³µ] '{extracted_keyword}'")
                        return extracted_keyword
            
            print(f"[âŒ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨] íŒŒì‹±í•  ìˆ˜ ì—†ëŠ” ì‘ë‹µ: '{qwen_response}'")
            return None
            
        except Exception as e:
            print(f"[â— Qwen í‚¤ì›Œë“œ ì¶”ì¶œ ì˜¤ë¥˜] {str(e)}")
            return None

    def _extract_date_with_qwen(self, user_input):
        """Qwenì„ ì‚¬ìš©í•˜ì—¬ ë‚ ì§œ ì •ë³´ ì¶”ì¶œ"""
        try:
            print(f"[ğŸ¤– Qwen ë‚ ì§œ ì¶”ì¶œ] '{user_input}'")
            
            # Qwen ëª¨ë¸ ë¡œë”©
            if not hasattr(self.ai_models, 'qwen_model') or self.ai_models.qwen_model is None:
                print("[ğŸ¤– Qwen ëª¨ë¸ ë¡œë”© ì‹œì‘]")
                self.ai_models.load_qwen_model()
            
            prompt = f"""í•œêµ­ì–´ ëª…ë ¹ì—ì„œ ë‚ ì§œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.
í˜•ì‹: date|ë‚ ì§œíƒ€ì…

ë‚ ì§œ íƒ€ì…:
- today: ì˜¤ëŠ˜
- yesterday: ì–´ì œ
- this_week: ì´ë²ˆì£¼, ì´ë²ˆ ì£¼
- last_week: ì§€ë‚œì£¼, ì§€ë‚œ ì£¼  
- this_month: ì´ë²ˆë‹¬, ì´ë²ˆ ë‹¬
- last_month: ì§€ë‚œë‹¬, ì§€ë‚œ ë‹¬
- none: ë‚ ì§œ ì—†ìŒ

ì˜ˆì‹œ:
"ì˜¤ëŠ˜ ë©”ì¼ ì°¾ì•„ì¤˜" â†’ date|today
"ì–´ì œ ë°›ì€ ë©”ì¼" â†’ date|yesterday
"ì§€ë‚œì£¼ íšŒì˜ë¡" â†’ date|last_week
"ì´ë²ˆë‹¬ ë³´ê³ ì„œ" â†’ date|this_month
"íšŒì˜ ë©”ì¼ ì°¾ì•„ì¤˜" â†’ date|none

ì…ë ¥: "{user_input}"
ê²°ê³¼:"""
            
            # í† í°í™”
            inputs = self.ai_models.qwen_tokenizer(prompt, return_tensors="pt")
            
            # ìƒì„±
            import torch
            with torch.no_grad():
                outputs = self.ai_models.qwen_model.generate(
                    inputs.input_ids,
                    max_new_tokens=15,  # ë‚ ì§œ ì •ë³´ëŠ” ë§¤ìš° ì§§ìŒ
                    do_sample=False,
                    temperature=0.1,
                    eos_token_id=self.ai_models.qwen_tokenizer.eos_token_id,
                    pad_token_id=self.ai_models.qwen_tokenizer.pad_token_id
                )
            
            generated_text = self.ai_models.qwen_tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            # ì‘ë‹µ ì¶”ì¶œ
            if "ê²°ê³¼:" in generated_text:
                qwen_response = generated_text.split("ê²°ê³¼:")[-1].strip()
            else:
                qwen_response = generated_text[len(prompt):].strip()
            
            print(f"[ğŸ¤– Qwen ì‘ë‹µ] {qwen_response}")
            
            # ì‘ë‹µ íŒŒì‹±: "date|value" í˜•ì‹
            lines = qwen_response.strip().split('\n')
            for line in lines:
                line = line.strip()
                if '|' in line and line.startswith('date|'):
                    parts = line.split('|', 1)
                    if len(parts) == 2:
                        date_type = parts[1].strip()
                        if date_type != "none":
                            print(f"[âœ… ë‚ ì§œ ì¶”ì¶œ ì„±ê³µ] '{date_type}'")
                            return date_type
            
            print(f"[ğŸ“… ë‚ ì§œ ì—†ìŒ] ë‚ ì§œ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
            
        except Exception as e:
            print(f"[â— Qwen ë‚ ì§œ ì¶”ì¶œ ì˜¤ë¥˜] {str(e)}")
            return None

    def _extract_limit_with_qwen(self, user_input):
        """Qwenì„ ì‚¬ìš©í•˜ì—¬ ê°œìˆ˜ ì œí•œ ì •ë³´ ì¶”ì¶œ"""
        try:
            print(f"[ğŸ¤– Qwen ê°œìˆ˜ ì¶”ì¶œ] '{user_input}'")
            
            # Qwen ëª¨ë¸ ë¡œë”©
            if not hasattr(self.ai_models, 'qwen_model') or self.ai_models.qwen_model is None:
                print("[ğŸ¤– Qwen ëª¨ë¸ ë¡œë”© ì‹œì‘]")
                self.ai_models.load_qwen_model()
            
            prompt = f"""í•œêµ­ì–´ ëª…ë ¹ì—ì„œ ê°œìˆ˜ ì œí•œì„ ì¶”ì¶œí•˜ì„¸ìš”.
í˜•ì‹: limit|ìˆ«ì

ê·œì¹™:
- ìˆ«ì+ê°œ íŒ¨í„´ ì°¾ê¸°
- ê°œìˆ˜ ì œí•œì´ ì—†ìœ¼ë©´ none

ì˜ˆì‹œ:
"ë©”ì¼ 5ê°œë§Œ ì°¾ì•„ì¤˜" â†’ limit|5
"ìµœì‹  ë©”ì¼ 10ê°œ ë³´ì—¬ì¤˜" â†’ limit|10
"3ê°œë§Œ í‘œì‹œí•´ì¤˜" â†’ limit|3
"íšŒì˜ ë©”ì¼ ì°¾ì•„ì¤˜" â†’ limit|none
"ìƒìœ„ 20ê°œ ë©”ì¼" â†’ limit|20

ì…ë ¥: "{user_input}"
ê²°ê³¼:"""
            
            # í† í°í™”
            inputs = self.ai_models.qwen_tokenizer(prompt, return_tensors="pt")
            
            # ìƒì„±
            import torch
            with torch.no_grad():
                outputs = self.ai_models.qwen_model.generate(
                    inputs.input_ids,
                    max_new_tokens=15,  # ê°œìˆ˜ ì •ë³´ëŠ” ë§¤ìš° ì§§ìŒ
                    do_sample=False,
                    temperature=0.1,
                    eos_token_id=self.ai_models.qwen_tokenizer.eos_token_id,
                    pad_token_id=self.ai_models.qwen_tokenizer.pad_token_id
                )
            
            generated_text = self.ai_models.qwen_tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            # ì‘ë‹µ ì¶”ì¶œ
            if "ê²°ê³¼:" in generated_text:
                qwen_response = generated_text.split("ê²°ê³¼:")[-1].strip()
            else:
                qwen_response = generated_text[len(prompt):].strip()
            
            print(f"[ğŸ¤– Qwen ì‘ë‹µ] {qwen_response}")
            
            # ì‘ë‹µ íŒŒì‹±: "limit|number" í˜•ì‹
            lines = qwen_response.strip().split('\n')
            for line in lines:
                line = line.strip()
                if '|' in line and line.startswith('limit|'):
                    parts = line.split('|', 1)
                    if len(parts) == 2:
                        limit_str = parts[1].strip()
                        if limit_str != "none" and limit_str.isdigit():
                            limit_num = int(limit_str)
                            print(f"[âœ… ê°œìˆ˜ ì¶”ì¶œ ì„±ê³µ] {limit_num}ê°œ")
                            return limit_num
            
            print(f"[ğŸ”¢ ê°œìˆ˜ ì—†ìŒ] ê°œìˆ˜ ì œí•œì´ ì—†ìŠµë‹ˆë‹¤")
            return None
            
        except Exception as e:
            print(f"[â— Qwen ê°œìˆ˜ ì¶”ì¶œ ì˜¤ë¥˜] {str(e)}")
            return None

    def _convert_date_type_to_filter(self, date_type):
        """Qwenì—ì„œ ì¶”ì¶œí•œ ë‚ ì§œ íƒ€ì…ì„ í•„í„°ë¡œ ë³€í™˜"""
        from datetime import datetime, timedelta
        
        today = datetime.now()
        
        if date_type == "today":
            start_date = today.replace(hour=0, minute=0, second=0, microsecond=0)
            end_date = today.replace(hour=23, minute=59, second=59, microsecond=999999)
            return {
                'type': 'today',
                'start_date': start_date,
                'end_date': end_date
            }
        elif date_type == "yesterday":
            yesterday = today - timedelta(days=1)
            start_date = yesterday.replace(hour=0, minute=0, second=0, microsecond=0)
            end_date = yesterday.replace(hour=23, minute=59, second=59, microsecond=999999)
            return {
                'type': 'yesterday',
                'start_date': start_date,
                'end_date': end_date
            }
        elif date_type == "this_week":
            days_since_monday = today.weekday()
            this_monday = today - timedelta(days=days_since_monday)
            start_date = this_monday.replace(hour=0, minute=0, second=0, microsecond=0)
            end_date = today.replace(hour=23, minute=59, second=59, microsecond=999999)
            return {
                'type': 'this_week',
                'start_date': start_date,
                'end_date': end_date
            }
        elif date_type == "last_week":
            days_since_monday = today.weekday()
            last_monday = today - timedelta(days=days_since_monday + 7)
            last_sunday = last_monday + timedelta(days=6)
            start_date = last_monday.replace(hour=0, minute=0, second=0, microsecond=0)
            end_date = last_sunday.replace(hour=23, minute=59, second=59, microsecond=999999)
            return {
                'type': 'last_week',
                'start_date': start_date,
                'end_date': end_date
            }
        elif date_type == "this_month":
            first_day_this_month = today.replace(day=1)
            start_date = first_day_this_month.replace(hour=0, minute=0, second=0, microsecond=0)
            end_date = today.replace(hour=23, minute=59, second=59, microsecond=999999)
            return {
                'type': 'this_month',
                'start_date': start_date,
                'end_date': end_date
            }
        elif date_type == "last_month":
            first_day_this_month = today.replace(day=1)
            last_day_last_month = first_day_this_month - timedelta(days=1)
            first_day_last_month = last_day_last_month.replace(day=1)
            start_date = first_day_last_month.replace(hour=0, minute=0, second=0, microsecond=0)
            end_date = last_day_last_month.replace(hour=23, minute=59, second=59, microsecond=999999)
            return {
                'type': 'last_month',
                'start_date': start_date,
                'end_date': end_date
            }
        
        return None

#     def _classify_intent_with_qwen(self, user_input):
#         """Qwenì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì˜ë„ ë¶„ë¥˜"""
#         try:
#             print(f"[ğŸ¤– Qwen Intent ë¶„ë¥˜] '{user_input}'")
            
#             # Qwen ëª¨ë¸ ë¡œë”©
#             if not hasattr(self.ai_models, 'qwen_model') or self.ai_models.qwen_model is None:
#                 print("[ğŸ¤– Qwen ëª¨ë¸ ë¡œë”© ì‹œì‘]")
#                 self.ai_models.load_qwen_model()
            
#             prompt = f"""í•œêµ­ì–´ ëª…ë ¹ì˜ ì˜ë„ë¥¼ ë¶„ë¥˜í•˜ì„¸ìš”.
# í˜•ì‹: intent|ì˜ë„íƒ€ì…

# ì˜ë„ íƒ€ì…:
# - grammar_correction: ë¬¸ë²•/ë§ì¶¤ë²• êµì • ìš”ì²­
# - email_search: í‚¤ì›Œë“œë¡œ ë©”ì¼ ê²€ìƒ‰
# - person_search: íŠ¹ì • ì‚¬ëŒì˜ ë©”ì¼ ê²€ìƒ‰  
# - email_statistics: ë©”ì¼ ê°œìˆ˜/í†µê³„ ì¡°íšŒ
# - settings_control: ì•± ì„¤ì • ë³€ê²½
# - generate_ai_reply: AI ë‹µì¥ ìƒì„±

# ì˜ˆì‹œ:
# "ì•ˆë…•í•˜ì„¸ìš” êµì •í•´ì£¼ì„¸ìš”" â†’ intent|grammar_correction
# "íšŒì˜ ê´€ë ¨ ë©”ì¼ ì°¾ì•„ì¤˜" â†’ intent|email_search
# "notion team ì´ë©”ì¼ ì°¾ì•„ì¤˜" â†’ intent|email_search
# "ê¹€ì² ìˆ˜ë‹˜ ë©”ì¼ ë³´ì—¬ì¤˜" â†’ intent|person_search
# "ì˜¤ëŠ˜ ë©”ì¼ ëª‡ ê°œ?" â†’ intent|email_statistics
# "í°íŠ¸ í¬ê¸° 18ë¡œ ë°”ê¿”ì¤˜" â†’ intent|settings_control
# "ë‹µì¥ ìƒì„±í•´ì¤˜" â†’ intent|generate_ai_reply

# ì…ë ¥: "{user_input}"
# ê²°ê³¼:"""
            
#             # í† í°í™”
#             inputs = self.ai_models.qwen_tokenizer(prompt, return_tensors="pt")
            
#             # ìƒì„±
#             import torch
#             with torch.no_grad():
#                 outputs = self.ai_models.qwen_model.generate(
#                     inputs.input_ids,
#                     max_new_tokens=20,  # IntentëŠ” ì§§ìŒ
#                     do_sample=False,
#                     temperature=0.1,
#                     eos_token_id=self.ai_models.qwen_tokenizer.eos_token_id,
#                     pad_token_id=self.ai_models.qwen_tokenizer.pad_token_id
#                 )
            
#             generated_text = self.ai_models.qwen_tokenizer.decode(outputs[0], skip_special_tokens=True)
            
#             # ì‘ë‹µ ì¶”ì¶œ
#             if "ê²°ê³¼:" in generated_text:
#                 qwen_response = generated_text.split("ê²°ê³¼:")[-1].strip()
#             else:
#                 qwen_response = generated_text[len(prompt):].strip()
            
#             print(f"[ğŸ¤– Qwen ì‘ë‹µ] {qwen_response}")
            
#             # ì‘ë‹µ íŒŒì‹±: "intent|type" í˜•ì‹
#             lines = qwen_response.strip().split('\n')
#             for line in lines:
#                 line = line.strip()
#                 if '|' in line and line.startswith('intent|'):
#                     parts = line.split('|', 1)
#                     if len(parts) == 2:
#                         intent_type = parts[1].strip()
#                         valid_intents = [
#                             'grammar_correction', 'email_search', 'person_search',
#                             'email_statistics', 'settings_control', 'generate_ai_reply'
#                         ]
#                         if intent_type in valid_intents:
#                             print(f"[âœ… Intent ë¶„ë¥˜ ì„±ê³µ] '{intent_type}'")
#                             return {
#                                 'action': intent_type,
#                                 'confidence': 0.9,  # Qwenì€ ë†’ì€ ì‹ ë¢°ë„
#                                 'method': 'qwen_intent',
#                                 'detailed_intent': f'{intent_type} classified by Qwen'
#                             }
            
#             print(f"[âŒ Intent ë¶„ë¥˜ ì‹¤íŒ¨] íŒŒì‹±í•  ìˆ˜ ì—†ëŠ” ì‘ë‹µ: '{qwen_response}'")
#             return None
            
#         except Exception as e:
#             print(f"[â— Qwen Intent ë¶„ë¥˜ ì˜¤ë¥˜] {str(e)}")
#             return None

#0826 ìˆ˜ì •
    def _classify_intent_with_qwen(self, user_input):
        """Qwen ê¸°ë°˜ ì •í™•í•œ ì˜ë„ ë¶„ì„"""
        # ìƒˆë¡œìš´ ë‹¨ìˆœ í˜•ì‹ íŒŒì‹±: "action, keyword"
        try:
            # NPUëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ í¬í•¨í•˜ì§€ ì•ŠëŠ” "ì‘ë‹µë§Œ" ë°˜í™˜í•œë‹¤ê³  ê°€ì •
            qwen_response = genie_analyze_intent(user_input)
            # ì•µì»¤ ì •ë¦¬
            #qwen_response = npu_out.split("ê²°ê³¼:", 1)[-1].strip() if "ê²°ê³¼:" in npu_out else npu_out.strip()

            # ë””ë²„ê·¸ (ë¡œê·¸ìš© ì „ì²´ ë¬¸ìì—´)
            # debug_prompt = qwen_prompt_command(user_input)
            # generated_text = _ensure_utf8(debug_prompt) + qwen_response
            # print(f"[ğŸ” ë””ë²„ê·¸] ì „ì²´ ìƒì„±ëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(generated_text)}")
            # print(f"[ğŸ” ë””ë²„ê·¸] ì „ì²´ ìƒì„± í…ìŠ¤íŠ¸ ì¼ë¶€: {generated_text[:200]}...")
            print(f"[ğŸ¤– NPU ì›ë³¸ ì‘ë‹µ] {qwen_response}")

            # ì‘ë‹µ íŒŒì‹±: "intent|type" í˜•ì‹
            lines = qwen_response.strip().split('\n')
            for line in lines:
                line = line.strip()
                if '|' in line and line.startswith('intent|'):
                    parts = line.split('|', 1)
                    if len(parts) == 2:
                        intent_type = parts[1].strip()
                        valid_intents = [
                            'grammar_correction', 'email_search', 'person_search',
                            'email_statistics', 'settings_control', 'generate_ai_reply'
                        ]
                        if intent_type in valid_intents:
                            print(f"[âœ… Intent ë¶„ë¥˜ ì„±ê³µ] '{intent_type}'")
                            return {
                                'action': intent_type,
                                'confidence': 0.9,  # Qwenì€ ë†’ì€ ì‹ ë¢°ë„
                                'method': 'qwen_intent',
                                'detailed_intent': f'{intent_type} classified by Qwen'
                            }

            # NPU ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨ â†’ ë‚´ë¶€ í‚¤ì›Œë“œ í´ë°±
            #print("[ğŸ”„ NPU í´ë°±] ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨, í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„ìœ¼ë¡œ ì „í™˜")
            #return self._parse_qwen_response_fallback(user_input, qwen_response)

        except Exception as ge:
            print(f"[âš ï¸ NPU(Genie) ì‹¤íŒ¨] {ge} â†’ HF(Qwen) ê²½ë¡œë¡œ í´ë°±")
        try:
            print(f"[ğŸ¤– Qwen Intent ë¶„ë¥˜] '{user_input}'")

            # Qwen ëª¨ë¸ ë¡œë”©
            if not hasattr(self.ai_models, 'qwen_model') or self.ai_models.qwen_model is None:
                print("[ğŸ¤– Qwen ëª¨ë¸ ë¡œë”© ì‹œì‘]")
                self.ai_models.load_qwen_model()

            prompt = f"""í•œêµ­ì–´ ëª…ë ¹ì˜ ì˜ë„ë¥¼ ë¶„ë¥˜í•˜ì„¸ìš”.
        í˜•ì‹: intent|ì˜ë„íƒ€ì…

        ì˜ë„ íƒ€ì…:
        - grammar_correction: ë¬¸ë²•/ë§ì¶¤ë²• êµì • ìš”ì²­
        - email_search: í‚¤ì›Œë“œë¡œ ë©”ì¼ ê²€ìƒ‰
        - person_search: íŠ¹ì • ì‚¬ëŒì˜ ë©”ì¼ ê²€ìƒ‰  
        - email_statistics: ë©”ì¼ ê°œìˆ˜/í†µê³„ ì¡°íšŒ
        - settings_control: ì•± ì„¤ì • ë³€ê²½
        - generate_ai_reply: AI ë‹µì¥ ìƒì„±

        ì˜ˆì‹œ:
        "ì•ˆë…•í•˜ì„¸ìš” êµì •í•´ì£¼ì„¸ìš”" â†’ intent|grammar_correction
        "íšŒì˜ ê´€ë ¨ ë©”ì¼ ì°¾ì•„ì¤˜" â†’ intent|email_search
        "notion team ì´ë©”ì¼ ì°¾ì•„ì¤˜" â†’ intent|email_search
        "ê¹€ì² ìˆ˜ë‹˜ ë©”ì¼ ë³´ì—¬ì¤˜" â†’ intent|person_search
        "ì˜¤ëŠ˜ ë©”ì¼ ëª‡ ê°œ?" â†’ intent|email_statistics
        "í°íŠ¸ í¬ê¸° 18ë¡œ ë°”ê¿”ì¤˜" â†’ intent|settings_control
        "ë‹µì¥ ìƒì„±í•´ì¤˜" â†’ intent|generate_ai_reply

        ì…ë ¥: "{user_input}"
        ê²°ê³¼:"""

            # í† í°í™”
            inputs = self.ai_models.qwen_tokenizer(prompt, return_tensors="pt")

            # ìƒì„±
            import torch
            with torch.no_grad():
                outputs = self.ai_models.qwen_model.generate(
                    inputs.input_ids,
                    max_new_tokens=20,  # IntentëŠ” ì§§ìŒ
                    do_sample=False,
                    temperature=0.1,
                    eos_token_id=self.ai_models.qwen_tokenizer.eos_token_id,
                    pad_token_id=self.ai_models.qwen_tokenizer.pad_token_id
                )

            generated_text = self.ai_models.qwen_tokenizer.decode(outputs[0], skip_special_tokens=True)

            # ì‘ë‹µ ì¶”ì¶œ
            if "ê²°ê³¼:" in generated_text:
                qwen_response = generated_text.split("ê²°ê³¼:")[-1].strip()
            else:
                qwen_response = generated_text[len(prompt):].strip()

            print(f"[ğŸ¤– Qwen ì‘ë‹µ] {qwen_response}")

            # ì‘ë‹µ íŒŒì‹±: "intent|type" í˜•ì‹
            lines = qwen_response.strip().split('\n')
            for line in lines:
                line = line.strip()
                if '|' in line and line.startswith('intent|'):
                    parts = line.split('|', 1)
                    if len(parts) == 2:
                        intent_type = parts[1].strip()
                        valid_intents = [
                            'grammar_correction', 'email_search', 'person_search',
                            'email_statistics', 'settings_control', 'generate_ai_reply'
                        ]
                        if intent_type in valid_intents:
                            print(f"[âœ… Intent ë¶„ë¥˜ ì„±ê³µ] '{intent_type}'")
                            return {
                                'action': intent_type,
                                'confidence': 0.9,  # Qwenì€ ë†’ì€ ì‹ ë¢°ë„
                                'method': 'qwen_intent',
                                'detailed_intent': f'{intent_type} classified by Qwen'
                            }

            print(f"[âŒ Intent ë¶„ë¥˜ ì‹¤íŒ¨] íŒŒì‹±í•  ìˆ˜ ì—†ëŠ” ì‘ë‹µ: '{qwen_response}'")
            return None

        except Exception as e:
            print(f"[â— Qwen Intent ë¶„ë¥˜ ì˜¤ë¥˜] {str(e)}")
            return None
        #0826 ë

    def _extract_search_target_with_qwen(self, text):
        """Qwenì„ ì´ìš©í•˜ì—¬ ê²€ìƒ‰ ëŒ€ìƒ ì¶”ì¶œ"""
        # Qwen ëª¨ë¸ì´ ë¡œë”©ë˜ì§€ ì•Šì•˜ë‹¤ë©´ ë¡œë”© ì‹œë„
        if not self.ai_models.load_qwen_model():
            print("[âš ï¸ Qwen ëª¨ë¸ ì—†ìŒ - ê°„ë‹¨ ì¶”ì¶œ ì‚¬ìš©]")
            words = text.split()
            return " ".join(words[-2:]) if len(words) >= 2 else text
        
        try:
            import torch
            prompt = (
                "<|im_start|>system\nYou are an email assistant. "
                "Your job is to extract the email address or name the user is referring to. "
                "You must always respond in the format: The user is referring to ... \n"
                "<|im_end|>\n"
                f"<|im_start|>user\n{text}<|im_end|>\n"
                "<|im_start|>assistant\n"
            )
            
            inputs = self.ai_models.qwen_tokenizer(prompt, return_tensors="pt").to(self.ai_models.qwen_model.device)
            
            with torch.no_grad():
                outputs = self.ai_models.qwen_model.generate(
                    **inputs,
                    max_new_tokens=50,
                    do_sample=False,
                    eos_token_id=self.ai_models.qwen_tokenizer.eos_token_id
                )
            
            decoded_output = self.ai_models.qwen_tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            # "assistant" ì´í›„ í…ìŠ¤íŠ¸ë§Œ ê°€ì ¸ì˜´
            if "assistant" in decoded_output:
                after_assistant = decoded_output.split("assistant")[-1].strip()
                prefix = "The user is referring to "
                if prefix in after_assistant:
                    result = after_assistant.split(prefix)[-1].strip().rstrip(".").strip('"')
                    return result
            
            return text
            
        except Exception as e:
            print(f"[âš ï¸ Qwen ì¶”ì¶œ ì˜¤ë¥˜] {str(e)}")
            # ì˜¤ë¥˜ ì‹œ ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œë¡œ fallback
            words = text.split()
            return " ".join(words[-2:]) if len(words) >= 2 else text
    
    def _handle_email_statistics(self, user_input, user_email, app_password):
        """ì´ë©”ì¼ í†µê³„ ì²˜ë¦¬"""
        try:
            from models.tables import Mail
            from models.db import db
            from datetime import datetime, timedelta
            import time
            
            start_time = time.time()
            
            print(f"\n{'='*50}")
            print(f"[ğŸ“Š í†µê³„ ìš”ì²­ ì‹œì‘] ì‚¬ìš©ì: {user_email}")
            print(f"[ğŸ“ í†µê³„ ëª…ë ¹ì–´] '{user_input}'")
            print(f"{'='*50}")
            
            user_input_lower = user_input.lower()
            
            # ì˜¤ëŠ˜ ë‚ ì§œ
            today = datetime.now().date()
            yesterday = today - timedelta(days=1)
            this_week_start = today - timedelta(days=today.weekday())
            this_month_start = today.replace(day=1)
            
            print(f"[ğŸ“… ë‚ ì§œ ê³„ì‚° ì™„ë£Œ]")
            print(f"  â€¢ ì˜¤ëŠ˜: {today}")
            print(f"  â€¢ ì–´ì œ: {yesterday}")
            print(f"  â€¢ ì´ë²ˆì£¼ ì‹œì‘: {this_week_start}")
            print(f"  â€¢ ì´ë²ˆë‹¬ ì‹œì‘: {this_month_start}")
            
            # ê¸°ë³¸ ì¿¼ë¦¬
            base_query = Mail.query.filter_by(user_email=user_email)
            print(f"[ğŸ—„ï¸ DB ì¿¼ë¦¬] ì‚¬ìš©ì '{user_email}' ë©”ì¼ ì¡°íšŒ ì¤€ë¹„")
            
            # í†µê³„ ê²°ê³¼ ì €ì¥
            stats_result = "ğŸ“Š **ì´ë©”ì¼ í†µê³„**\n\n"
            
            # 1. ì˜¤ëŠ˜ ê´€ë ¨ í†µê³„
            if any(keyword in user_input_lower for keyword in ["ì˜¤ëŠ˜", "today"]):
                print(f"[ğŸ¯ í†µê³„ ìœ í˜•] ì˜¤ëŠ˜ ë©”ì¼ í†µê³„ ìš”ì²­")
                
                print(f"[ğŸ” DB ì¡°íšŒ] ì˜¤ëŠ˜ ë°›ì€ë©”ì¼ ê°œìˆ˜ ê³„ì‚° ì¤‘...")
                today_inbox = base_query.filter(
                    db.func.date(Mail.date) == today,
                    Mail.mail_type == 'inbox'
                ).count()
                
                print(f"[ğŸ” DB ì¡°íšŒ] ì˜¤ëŠ˜ ë³´ë‚¸ë©”ì¼ ê°œìˆ˜ ê³„ì‚° ì¤‘...")
                today_sent = base_query.filter(
                    db.func.date(Mail.date) == today,
                    Mail.mail_type == 'sent'
                ).count()
                
                print(f"[ğŸ“Š ê³„ì‚° ê²°ê³¼] ì˜¤ëŠ˜ ë°›ì€ë©”ì¼: {today_inbox}ê°œ, ë³´ë‚¸ë©”ì¼: {today_sent}ê°œ, ì´ {today_inbox + today_sent}ê°œ")
                
                stats_result += f"ğŸ“… **ì˜¤ëŠ˜ ({today.strftime('%Y-%m-%d')})**\n"
                stats_result += f"ğŸ“¥ ë°›ì€ ë©”ì¼: **{today_inbox}ê°œ**\n"
                stats_result += f"ğŸ“¤ ë³´ë‚¸ ë©”ì¼: **{today_sent}ê°œ**\n"
                stats_result += f"ğŸ“Š ì´í•©: **{today_inbox + today_sent}ê°œ**\n\n"
            
            # 2. ì–´ì œ ê´€ë ¨ í†µê³„
            elif any(keyword in user_input_lower for keyword in ["ì–´ì œ", "yesterday"]):
                print(f"[ğŸ¯ í†µê³„ ìœ í˜•] ì–´ì œ ë©”ì¼ í†µê³„ ìš”ì²­")
                
                print(f"[ğŸ” DB ì¡°íšŒ] ì–´ì œ ë°›ì€ë©”ì¼ ê°œìˆ˜ ê³„ì‚° ì¤‘...")
                yesterday_inbox = base_query.filter(
                    db.func.date(Mail.date) == yesterday,
                    Mail.mail_type == 'inbox'
                ).count()
                
                print(f"[ğŸ” DB ì¡°íšŒ] ì–´ì œ ë³´ë‚¸ë©”ì¼ ê°œìˆ˜ ê³„ì‚° ì¤‘...")
                yesterday_sent = base_query.filter(
                    db.func.date(Mail.date) == yesterday,
                    Mail.mail_type == 'sent'
                ).count()
                
                print(f"[ğŸ“Š ê³„ì‚° ê²°ê³¼] ì–´ì œ ë°›ì€ë©”ì¼: {yesterday_inbox}ê°œ, ë³´ë‚¸ë©”ì¼: {yesterday_sent}ê°œ, ì´ {yesterday_inbox + yesterday_sent}ê°œ")
                
                stats_result += f"ğŸ“… **ì–´ì œ ({yesterday.strftime('%Y-%m-%d')})**\n"
                stats_result += f"ğŸ“¥ ë°›ì€ ë©”ì¼: **{yesterday_inbox}ê°œ**\n"
                stats_result += f"ğŸ“¤ ë³´ë‚¸ ë©”ì¼: **{yesterday_sent}ê°œ**\n"
                stats_result += f"ğŸ“Š ì´í•©: **{yesterday_inbox + yesterday_sent}ê°œ**\n\n"
            
            # 3. ì´ë²ˆì£¼ ê´€ë ¨ í†µê³„
            elif any(keyword in user_input_lower for keyword in ["ì´ë²ˆì£¼", "ì´ë²ˆ ì£¼", "this week"]):
                print(f"[ğŸ¯ í†µê³„ ìœ í˜•] ì´ë²ˆì£¼ ë©”ì¼ í†µê³„ ìš”ì²­")
                
                print(f"[ğŸ” DB ì¡°íšŒ] ì´ë²ˆì£¼ ë°›ì€ë©”ì¼ ê°œìˆ˜ ê³„ì‚° ì¤‘...")
                week_inbox = base_query.filter(
                    Mail.date >= this_week_start,
                    Mail.mail_type == 'inbox'
                ).count()
                
                print(f"[ğŸ” DB ì¡°íšŒ] ì´ë²ˆì£¼ ë³´ë‚¸ë©”ì¼ ê°œìˆ˜ ê³„ì‚° ì¤‘...")
                week_sent = base_query.filter(
                    Mail.date >= this_week_start,
                    Mail.mail_type == 'sent'
                ).count()
                
                print(f"[ğŸ“Š ê³„ì‚° ê²°ê³¼] ì´ë²ˆì£¼ ë°›ì€ë©”ì¼: {week_inbox}ê°œ, ë³´ë‚¸ë©”ì¼: {week_sent}ê°œ, ì´ {week_inbox + week_sent}ê°œ")
                
                stats_result += f"ğŸ“… **ì´ë²ˆì£¼ ({this_week_start.strftime('%Y-%m-%d')} ~ {today.strftime('%Y-%m-%d')})**\n"
                stats_result += f"ğŸ“¥ ë°›ì€ ë©”ì¼: **{week_inbox}ê°œ**\n"
                stats_result += f"ğŸ“¤ ë³´ë‚¸ ë©”ì¼: **{week_sent}ê°œ**\n"
                stats_result += f"ğŸ“Š ì´í•©: **{week_inbox + week_sent}ê°œ**\n\n"
            
            # 4. ì´ë²ˆë‹¬ ê´€ë ¨ í†µê³„
            elif any(keyword in user_input_lower for keyword in ["ì´ë²ˆë‹¬", "ì´ë²ˆ ë‹¬", "this month"]):
                print(f"[ğŸ¯ í†µê³„ ìœ í˜•] ì´ë²ˆë‹¬ ë©”ì¼ í†µê³„ ìš”ì²­")
                
                print(f"[ğŸ” DB ì¡°íšŒ] ì´ë²ˆë‹¬ ë°›ì€ë©”ì¼ ê°œìˆ˜ ê³„ì‚° ì¤‘...")
                month_inbox = base_query.filter(
                    Mail.date >= this_month_start,
                    Mail.mail_type == 'inbox'
                ).count()
                
                print(f"[ğŸ” DB ì¡°íšŒ] ì´ë²ˆë‹¬ ë³´ë‚¸ë©”ì¼ ê°œìˆ˜ ê³„ì‚° ì¤‘...")
                month_sent = base_query.filter(
                    Mail.date >= this_month_start,
                    Mail.mail_type == 'sent'
                ).count()
                
                print(f"[ğŸ“Š ê³„ì‚° ê²°ê³¼] ì´ë²ˆë‹¬ ë°›ì€ë©”ì¼: {month_inbox}ê°œ, ë³´ë‚¸ë©”ì¼: {month_sent}ê°œ, ì´ {month_inbox + month_sent}ê°œ")
                
                stats_result += f"ğŸ“… **ì´ë²ˆë‹¬ ({this_month_start.strftime('%Y-%m')})**\n"
                stats_result += f"ğŸ“¥ ë°›ì€ ë©”ì¼: **{month_inbox}ê°œ**\n"
                stats_result += f"ğŸ“¤ ë³´ë‚¸ ë©”ì¼: **{month_sent}ê°œ**\n"
                stats_result += f"ğŸ“Š ì´í•©: **{month_inbox + month_sent}ê°œ**\n\n"
            
            # 5. ì „ì²´ í†µê³„ (ê¸°ë³¸ê°’)
            else:
                print(f"[ğŸ¯ í†µê³„ ìœ í˜•] ì „ì²´ ë©”ì¼ í†µê³„ ìš”ì²­")
                
                print(f"[ğŸ” DB ì¡°íšŒ] ì „ì²´ ë°›ì€ë©”ì¼ ê°œìˆ˜ ê³„ì‚° ì¤‘...")
                total_inbox = base_query.filter_by(mail_type='inbox').count()
                
                print(f"[ğŸ” DB ì¡°íšŒ] ì „ì²´ ë³´ë‚¸ë©”ì¼ ê°œìˆ˜ ê³„ì‚° ì¤‘...")
                total_sent = base_query.filter_by(mail_type='sent').count()
                
                print(f"[ğŸ” DB ì¡°íšŒ] ìµœê·¼ ë©”ì¼ ì •ë³´ ì¡°íšŒ ì¤‘...")
                # ìµœê·¼ ë©”ì¼ ë‚ ì§œ
                latest_mail = base_query.order_by(Mail.date.desc()).first()
                oldest_mail = base_query.order_by(Mail.date.asc()).first()
                
                print(f"[ğŸ“Š ê³„ì‚° ê²°ê³¼] ì „ì²´ ë°›ì€ë©”ì¼: {total_inbox}ê°œ, ë³´ë‚¸ë©”ì¼: {total_sent}ê°œ, ì´ {total_inbox + total_sent}ê°œ")
                if latest_mail:
                    print(f"[ğŸ“… ìµœì‹  ë©”ì¼] {latest_mail.date.strftime('%Y-%m-%d %H:%M')}")
                if oldest_mail:
                    print(f"[ğŸ“… ê°€ì¥ ì˜¤ë˜ëœ ë©”ì¼] {oldest_mail.date.strftime('%Y-%m-%d %H:%M')}")
                
                stats_result += f"ğŸ“Š **ì „ì²´ ì´ë©”ì¼ í†µê³„**\n"
                stats_result += f"ğŸ“¥ ì´ ë°›ì€ ë©”ì¼: **{total_inbox}ê°œ**\n"
                stats_result += f"ğŸ“¤ ì´ ë³´ë‚¸ ë©”ì¼: **{total_sent}ê°œ**\n"
                stats_result += f"ğŸ“ˆ ì „ì²´ ì´í•©: **{total_inbox + total_sent}ê°œ**\n\n"
                
                if latest_mail:
                    stats_result += f"ğŸ“… **ìµœê·¼ ë©”ì¼**: {latest_mail.date.strftime('%Y-%m-%d %H:%M')}\n"
                if oldest_mail:
                    stats_result += f"ğŸ“… **ê°€ì¥ ì˜¤ë˜ëœ ë©”ì¼**: {oldest_mail.date.strftime('%Y-%m-%d %H:%M')}\n\n"
                
                # ë°›ì€ë©”ì¼ vs ë³´ë‚¸ë©”ì¼ ë¹„ìœ¨
                if total_inbox + total_sent > 0:
                    inbox_ratio = (total_inbox / (total_inbox + total_sent)) * 100
                    sent_ratio = (total_sent / (total_inbox + total_sent)) * 100
                    print(f"[ğŸ“ˆ ë¹„ìœ¨ ê³„ì‚°] ë°›ì€ë©”ì¼: {inbox_ratio:.1f}%, ë³´ë‚¸ë©”ì¼: {sent_ratio:.1f}%")
                    stats_result += f"ğŸ“Š **ë¹„ìœ¨**\n"
                    stats_result += f"ğŸ“¥ ë°›ì€ë©”ì¼: {inbox_ratio:.1f}%\n"
                    stats_result += f"ğŸ“¤ ë³´ë‚¸ë©”ì¼: {sent_ratio:.1f}%\n\n"
            
            # ì¶”ê°€ ì •ë³´
            stats_result += "ğŸ’¡ **ë” ìì„¸í•œ í†µê³„**\n"
            stats_result += "â€¢ 'ì˜¤ëŠ˜ ë©”ì¼ ëª‡ ê°œ?' - ì˜¤ëŠ˜ í†µê³„\n"
            stats_result += "â€¢ 'ì´ë²ˆì£¼ ë©”ì¼ ê°œìˆ˜' - ì£¼ê°„ í†µê³„\n"
            stats_result += "â€¢ 'ì´ë²ˆë‹¬ ë©”ì¼ í†µê³„' - ì›”ê°„ í†µê³„\n"
            stats_result += "â€¢ 'ì–´ì œ ë©”ì¼ ëª‡ ê°œ?' - ì–´ì œ í†µê³„"
            
            # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            processing_time = time.time() - start_time
            print(f"[â±ï¸ í†µê³„ ì²˜ë¦¬ ì™„ë£Œ] ì´ ì†Œìš”ì‹œê°„: {processing_time:.3f}ì´ˆ")
            print(f"[âœ… í†µê³„ ì‘ë‹µ ìƒì„± ì™„ë£Œ] ì‘ë‹µ ê¸¸ì´: {len(stats_result)}ì")
            print(f"{'='*50}\n")
            
            return stats_result
            
        except Exception as e:
            print(f"[â—í†µê³„ ì²˜ë¦¬ ì˜¤ë¥˜] {str(e)}")
            print(f"{'='*50}\n")
            return "âŒ í†µê³„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    def _handle_date_search(self, user_input, user_email, app_password):
        """ë‚ ì§œë³„ ê²€ìƒ‰ ì „ìš© í•¸ë“¤ëŸ¬"""
        print(f"[ğŸ“… ë‚ ì§œë³„ ê²€ìƒ‰] ì…ë ¥: '{user_input}'")
        
        # ë‚ ì§œ í•„í„°ë¥¼ ìš°ì„ ì ìœ¼ë¡œ íŒŒì‹±
        date_filter = self._parse_date_keywords(user_input)
        
        if not date_filter:
            # ë‚ ì§œ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì˜¤ëŠ˜ ê¸°ë³¸ê°’
            from datetime import datetime
            today = datetime.now()
            date_filter = {
                'type': 'today',
                'start_date': today.replace(hour=0, minute=0, second=0, microsecond=0),
                'end_date': today.replace(hour=23, minute=59, second=59, microsecond=999999)
            }
            
        # ì¶”ê°€ í•„í„° íŒŒì‹±
        limit_count = self._parse_limit_keywords(user_input)
        mail_type_filter = self._parse_mail_type_keywords(user_input)
        
        # ë‚ ì§œ ì¤‘ì‹¬ ê²€ìƒ‰ ì‹¤í–‰
        return self._execute_search_with_filters(
            user_email, app_password, user_input, 
            date_filter, limit_count, mail_type_filter,
            focus="date"
        )
    
    def _handle_limit_search(self, user_input, user_email, app_password):
        """ê°œìˆ˜ ì œí•œ ê²€ìƒ‰ ì „ìš© í•¸ë“¤ëŸ¬"""
        print(f"[ğŸ”¢ ê°œìˆ˜ ì œí•œ ê²€ìƒ‰] ì…ë ¥: '{user_input}'")
        
        # Qwenìœ¼ë¡œ ê°œìˆ˜ ì œí•œ ì¶”ì¶œ
        qwen_limit = self._extract_limit_with_qwen(user_input)
        limit_count = qwen_limit if qwen_limit else 5  # ê¸°ë³¸ 5ê°œ
        
        # Qwenìœ¼ë¡œ ë‚ ì§œ í•„í„° ì¶”ì¶œ  
        qwen_date = self._extract_date_with_qwen(user_input)
        date_filter = self._convert_date_type_to_filter(qwen_date) if qwen_date else None
        
        mail_type_filter = self._parse_mail_type_keywords(user_input)
        
        # ê°œìˆ˜ ì œí•œ ê²€ìƒ‰ (í‚¤ì›Œë“œ ì—†ì´ ìµœì‹  ë©”ì¼ë§Œ)
        print(f"[ğŸ”¢ ì œí•œ ê²€ìƒ‰ ì‹¤í–‰] ê°œìˆ˜: {limit_count}ê°œ")
        
        found_emails = self._search_emails_in_db(
            user_email, 
            search_keywords="",  # í‚¤ì›Œë“œ ì—†ìŒ
            max_results=limit_count,
            date_filter=date_filter,
            mail_type_filter=mail_type_filter,
            limit_count=limit_count
        )
        
        if found_emails:
            result = f"ğŸ“¬ **ìµœì‹  ë©”ì¼ {limit_count}ê°œ**\n\n"
            for i, mail_info in enumerate(found_emails, 1):
                result += f"**{i}. {mail_info['subject']}**\n"
                result += f"ğŸ‘¤ {mail_info['from']}\n"
                result += f"ğŸ“… {mail_info['date']}\n\n"
            return result
        else:
            return f"ğŸ“­ ë©”ì¼ì´ ì—†ìŠµë‹ˆë‹¤."
    
    def _handle_type_search(self, user_input, user_email, app_password):
        """ë©”ì¼ íƒ€ì…ë³„ ê²€ìƒ‰ ì „ìš© í•¸ë“¤ëŸ¬"""
        print(f"[ğŸ“§ íƒ€ì…ë³„ ê²€ìƒ‰] ì…ë ¥: '{user_input}'")
        
        # ë©”ì¼ íƒ€ì…ì„ ìš°ì„ ì ìœ¼ë¡œ íŒŒì‹±
        mail_type_filter = self._parse_mail_type_keywords(user_input)
        
        if not mail_type_filter:
            # íƒ€ì…ì´ ëª…ì‹œë˜ì§€ ì•Šìœ¼ë©´ ë°›ì€ë©”ì¼ ê¸°ë³¸ê°’
            mail_type_filter = "inbox"
            
        # ì¶”ê°€ í•„í„° íŒŒì‹±
        date_filter = self._parse_date_keywords(user_input)
        limit_count = self._parse_limit_keywords(user_input)
        
        # íƒ€ì… ì¤‘ì‹¬ ê²€ìƒ‰ ì‹¤í–‰
        return self._execute_search_with_filters(
            user_email, app_password, user_input,
            date_filter, limit_count, mail_type_filter,
            focus="type"
        )
    
    def _handle_complex_search(self, user_input, user_email, app_password):
        """ë³µí•© ì¡°ê±´ ê²€ìƒ‰ ì „ìš© í•¸ë“¤ëŸ¬"""
        print(f"[ğŸ”„ ë³µí•© ê²€ìƒ‰] ì…ë ¥: '{user_input}'")
        
        # ëª¨ë“  í•„í„°ë¥¼ ë™ë“±í•˜ê²Œ íŒŒì‹±
        date_filter = self._parse_date_keywords(user_input)
        limit_count = self._parse_limit_keywords(user_input)
        mail_type_filter = self._parse_mail_type_keywords(user_input)
        
        # ì‚¬ëŒ ì´ë¦„ë„ ì¶”ì¶œ
        person_name = self._extract_person_name(user_input)
        
        if person_name:
            # ì‚¬ëŒë³„ + ë³µí•© ì¡°ê±´
            return self._handle_person_search_with_filters(
                user_input, user_email, app_password,
                person_name, date_filter, limit_count, mail_type_filter
            )
        else:
            # ì¼ë°˜ ë³µí•© ê²€ìƒ‰
            return self._execute_search_with_filters(
                user_email, app_password, user_input,
                date_filter, limit_count, mail_type_filter,
                focus="complex"
            )
    
    def _execute_search_with_filters(self, user_email, app_password, user_input, 
                                    date_filter, limit_count, mail_type_filter, focus="general"):
        """í•„í„°ë¥¼ ì ìš©í•œ ê²€ìƒ‰ ì‹¤í–‰"""
        try:
            # ê²€ìƒ‰ í‚¤ì›Œë“œ ì¶”ì¶œ
            search_keywords = self._clean_search_keywords(user_input, date_filter, limit_count, mail_type_filter)
            
            print(f"[ğŸ¯ {focus} ê²€ìƒ‰ ì‹¤í–‰] í‚¤ì›Œë“œ: '{search_keywords}', ë‚ ì§œ: {date_filter}, ê°œìˆ˜: {limit_count}, íƒ€ì…: {mail_type_filter}")
            
            # DB ê²€ìƒ‰ ì‹¤í–‰
            results = self._search_emails_in_db(
                user_email, 
                search_keywords,
                date_filter=date_filter,
                mail_type_filter=mail_type_filter,
                limit_count=limit_count
            )
            
            # ê²°ê³¼ í¬ë§·íŒ…
            return self._format_search_results(results, search_keywords, focus)
            
        except Exception as e:
            print(f"[â—ê²€ìƒ‰ ì‹¤í–‰ ì˜¤ë¥˜] {str(e)}")
            return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def _clean_search_keywords(self, user_input, date_filter, limit_count, mail_type_filter):
        """ê²€ìƒ‰ í‚¤ì›Œë“œ ì •ë¦¬ - ìµœì†Œí•œì˜ ì²˜ë¦¬ë§Œ"""
        keywords = user_input
        
        # ì˜¤ì§ ì´ë¯¸ ì¶”ì¶œëœ í•„í„° í‚¤ì›Œë“œë§Œ ì œê±° (ì¤‘ë³µ ë°©ì§€)
        if date_filter:
            date_keywords = ["ì˜¤ëŠ˜", "ì–´ì œ", "ê·¸ì œ", "ì§€ë‚œì£¼", "ì´ë²ˆì£¼", "ì´ë²ˆë‹¬", "ì§€ë‚œë‹¬", "ìµœê·¼"]
            for kw in date_keywords:
                if kw in keywords:
                    keywords = keywords.replace(kw, "")
        
        if limit_count:
            import re
            # ìˆ«ì+ê°œ íŒ¨í„´ë§Œ ì œê±° (ì´ë¯¸ limit_countë¡œ ì¶”ì¶œë¨)
            keywords = re.sub(r'\d+ê°œ\s*ë§Œ?', '', keywords)
            if "ìµœì‹ " in keywords:
                keywords = keywords.replace("ìµœì‹ ", "")
        
        if mail_type_filter:
            # ë©”ì¼ íƒ€ì… í‚¤ì›Œë“œë§Œ ì œê±° (ì´ë¯¸ mail_type_filterë¡œ ì¶”ì¶œë¨)
            if "ë°›ì€ë©”ì¼" in keywords:
                keywords = keywords.replace("ë°›ì€ë©”ì¼", "")
            if "ë³´ë‚¸ë©”ì¼" in keywords:
                keywords = keywords.replace("ë³´ë‚¸ë©”ì¼", "")
        
        # ê³µë°± ì •ë¦¬ë§Œ
        keywords = re.sub(r'\s+', ' ', keywords.strip())
        
        return keywords
    
    def _format_search_results(self, results, search_keywords, focus):
        """ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…"""
        if not results:
            return f"âŒ '{search_keywords}'ì™€ ê´€ë ¨ëœ ë©”ì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # í¬ì»¤ìŠ¤ì— ë”°ë¥¸ ì œëª© ì„¤ì •
        focus_titles = {
            "date": "ğŸ“… ë‚ ì§œë³„ ê²€ìƒ‰ ê²°ê³¼",
            "limit": "ğŸ”¢ ê°œìˆ˜ ì œí•œ ê²€ìƒ‰ ê²°ê³¼", 
            "type": "ğŸ“§ íƒ€ì…ë³„ ê²€ìƒ‰ ê²°ê³¼",
            "complex": "ğŸ”„ ë³µí•© ê²€ìƒ‰ ê²°ê³¼",
            "general": "ğŸ” ê²€ìƒ‰ ê²°ê³¼"
        }
        
        response = f"{focus_titles.get(focus, 'ğŸ” ê²€ìƒ‰ ê²°ê³¼')}\n\n"
        response += f"ê²€ìƒ‰ëœ ë©”ì¼: {len(results)}ê°œ\n\n"
        
        for idx, mail in enumerate(results, 1):
            response += f"**{idx}. {mail['subject']}**\n"
            response += f"ğŸ“¤ ë°œì‹ ì: {mail['from']}\n"
            response += f"ğŸ“… ë‚ ì§œ: {mail['date']}\n"
            if mail.get('mail_type'):
                type_label = "ë°›ì€ë©”ì¼" if mail['mail_type'] == 'inbox' else "ë³´ë‚¸ë©”ì¼"
                response += f"ğŸ“§ íƒ€ì…: {type_label}\n"
            response += f"ğŸ“ ë‚´ìš©: {mail['body'][:100]}...\n\n"
        
        return response
    
    def _handle_person_search_with_filters(self, user_input, user_email, app_password, 
                                          person_name, date_filter, limit_count, mail_type_filter):
        """ì‚¬ëŒë³„ ê²€ìƒ‰ + ì¶”ê°€ í•„í„°"""
        try:
            print(f"[ğŸ‘¤ ì‚¬ëŒë³„ ë³µí•© ê²€ìƒ‰] ì‚¬ëŒ: '{person_name}', ë‚ ì§œ: {date_filter}, ê°œìˆ˜: {limit_count}, íƒ€ì…: {mail_type_filter}")
            
            # ì‚¬ëŒ ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰
            results = self._search_emails_in_db(
                user_email,
                person_name,
                date_filter=date_filter,
                mail_type_filter=mail_type_filter, 
                limit_count=limit_count
            )
            
            # ê²°ê³¼ í¬ë§·íŒ…
            if not results:
                return f"âŒ '{person_name}'ë‹˜ì˜ ë©”ì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            response = f"ğŸ‘¤ **{person_name}ë‹˜ ë©”ì¼ ê²€ìƒ‰ ê²°ê³¼**\n\n"
            response += f"ê²€ìƒ‰ëœ ë©”ì¼: {len(results)}ê°œ\n\n"
            
            for idx, mail in enumerate(results, 1):
                response += f"**{idx}. {mail['subject']}**\n"
                response += f"ğŸ“… ë‚ ì§œ: {mail['date']}\n"
                response += f"ğŸ“ ë‚´ìš©: {mail['body'][:100]}...\n\n"
            
            return response
            
        except Exception as e:
            print(f"[â—ì‚¬ëŒë³„ ë³µí•© ê²€ìƒ‰ ì˜¤ë¥˜] {str(e)}")
            return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def _extract_person_name(self, user_input):
        """ì…ë ¥ì—ì„œ ì‚¬ëŒ ì´ë¦„ ì¶”ì¶œ"""
        # ë‹˜, ì”¨, êµìˆ˜, ì„ ìƒ ë“±ì˜ í˜¸ì¹­ì´ ìˆëŠ” ê²½ìš°
        import re
        
        patterns = [
            r'([ê°€-í£]+)(?:ë‹˜|ì”¨|êµìˆ˜|ì„ ìƒ)',
            r'([a-zA-Z\s]+)(?:ë‹˜|ì”¨)',
            r'from\s+([a-zA-Z\s]+)',
            r'([ê°€-í£]{2,4})(?:\s|ì˜|ì—ê²Œ|í•œí…Œ|ë¡œë¶€í„°)'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, user_input)
            if match:
                return match.group(1).strip()
        
        return None
    
    def _handle_unknown_intent(self):
        """ì•Œ ìˆ˜ ì—†ëŠ” ì˜ë„ ì²˜ë¦¬"""
        return """â“ ìš”ì²­ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‘œí˜„ì„ ì‹œë„í•´ì£¼ì„¸ìš”.

ğŸ”§ **ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥ë“¤:**
â€¢ **ë¬¸ë²•/ë§ì¶¤ë²• êµì •**: "ì´ ë¬¸ì¥ êµì •í•´ì£¼ì„¸ìš”" / "correct this sentence"
â€¢ **ì´ë¯¸ì§€ ìƒì„±**: "ê³ ì–‘ì´ ê·¸ë¦¼ ê·¸ë ¤ì¤˜" / "generate cat image"  
â€¢ **ë©”ì¼ ê²€ìƒ‰**: "íšŒì˜ ê´€ë ¨ ë©”ì¼ ì°¾ì•„ì¤˜" / "find meeting emails"
â€¢ **ì‚¬ëŒë³„ ë©”ì¼**: "ê¹€ì² ìˆ˜ë‹˜ ë©”ì¼ ê²€ìƒ‰" / "search john@company.com emails"

ğŸ’¡ **Example / ì˜ˆì‹œ:**
- í•œêµ­ì–´: "ì•ˆë…•í•˜ì„¸ìš”. ì œê°€ ì˜¤ëŠ˜ íšŒì˜ì— ì°¸ì„ëª»í• ê²ƒ ê°™ìŠµë‹ˆë‹¤ êµì •í•´ì£¼ì„¸ìš”"
- English: "correct the grammar: I can't attend meeting today"
- í˜¼í•©: "find í”„ë¡œì íŠ¸ ê´€ë ¨ emails" """

    

    def _search_emails_in_db(self, user_email, search_keywords, max_results=50, date_filter=None, mail_type_filter=None, limit_count=None):
        """DBì—ì„œ ì´ë©”ì¼ ê²€ìƒ‰ (ë‚ ì§œ/íƒ€ì…/ê°œìˆ˜ ì œí•œ ì§€ì›)"""
        try:
            from models.tables import Mail
            from models.db import db
            import re
            
            print(f"[ğŸ” ê³ ê¸‰ ê²€ìƒ‰ ì‹œì‘] í‚¤ì›Œë“œ: '{search_keywords}'")
            if date_filter:
                print(f"[ğŸ“… ë‚ ì§œ í•„í„°] {date_filter}")
            if mail_type_filter:
                print(f"[ğŸ“§ íƒ€ì… í•„í„°] {mail_type_filter}")
            if limit_count:
                print(f"[ğŸ”¢ ê°œìˆ˜ ì œí•œ] {limit_count}ê°œ")
            
            # ê¸°ë³¸ ì¿¼ë¦¬ ìƒì„±
            query = Mail.query.filter_by(user_email=user_email)
            
            # ë‚ ì§œ í•„í„° ì¶”ê°€
            if date_filter:
                start_date = date_filter.get('start_date')
                end_date = date_filter.get('end_date')
                
                if start_date and end_date:
                    print(f"[ğŸ“… ë‚ ì§œ ë²”ìœ„] {start_date} ~ {end_date}")
                    query = query.filter(
                        Mail.date >= start_date,
                        Mail.date <= end_date
                    )
                elif start_date:
                    print(f"[ğŸ“… ì‹œì‘ ë‚ ì§œ] {start_date} ì´í›„")
                    query = query.filter(Mail.date >= start_date)
                elif end_date:
                    print(f"[ğŸ“… ì¢…ë£Œ ë‚ ì§œ] {end_date} ì´ì „")
                    query = query.filter(Mail.date <= end_date)
            
            # ë©”ì¼ íƒ€ì… í•„í„° ì¶”ê°€
            if mail_type_filter:
                query = query.filter(Mail.mail_type == mail_type_filter)
            
            # ì´ë©”ì¼ ì£¼ì†Œ íŒ¨í„´ í™•ì¸
            email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
            email_found = re.search(email_pattern, search_keywords)
            
            if email_found:
                # ì´ë©”ì¼ ì£¼ì†Œë¡œ ê²€ìƒ‰ (ë°œì‹ ì ê¸°ì¤€)
                search_email = email_found.group()
                print(f"[ğŸ¯ ì´ë©”ì¼ ì£¼ì†Œ ê²€ìƒ‰] {search_email}")
                
                query = query.filter(Mail.from_.contains(search_email))
                
            else:
                # í‚¤ì›Œë“œë¡œ ì œëª©/ë‚´ìš©/ë°œì‹ ì ê²€ìƒ‰
                print(f"[ğŸ¯ í‚¤ì›Œë“œ ê²€ìƒ‰] {search_keywords}")
                
                query = query.filter(
                    db.or_(
                        Mail.subject.contains(search_keywords),
                        Mail.body.contains(search_keywords),
                        Mail.from_.contains(search_keywords),
                        Mail.summary.contains(search_keywords)
                    )
                )
            
            # ì •ë ¬ ë° ê°œìˆ˜ ì œí•œ
            final_limit = limit_count if limit_count else max_results
            db_results = query.order_by(Mail.date.desc()).limit(final_limit).all()
            
            # ê²°ê³¼ë¥¼ ê¸°ì¡´ í˜•íƒœë¡œ ë³€í™˜
            found_emails = []
            for mail in db_results:
                found_emails.append({
                    'id': mail.mail_id,
                    'subject': mail.subject[:60] + "..." if len(mail.subject) > 60 else mail.subject,
                    'from': mail.from_[:40] + "..." if len(mail.from_) > 40 else mail.from_,
                    'date': mail.date.strftime('%Y-%m-%d %H:%M:%S'),
                    'preview': mail.body[:200] + "..." if len(mail.body) > 200 else mail.body,
                    'classification': mail.classification,
                    'summary': mail.summary
                })
            
            print(f"[âœ… ì±—ë´‡ DB ê²€ìƒ‰] {len(found_emails)}ê°œ ê²°ê³¼")
            return found_emails
            
        except Exception as e:
            print(f"[â— ì±—ë´‡ DB ê²€ìƒ‰ ì‹¤íŒ¨] {str(e)}")
            return []
    
    def _parse_date_keywords(self, user_input):
        """ì‚¬ìš©ì ì…ë ¥ì—ì„œ ë‚ ì§œ í‚¤ì›Œë“œ íŒŒì‹±"""
        try:
            from datetime import datetime, timedelta
            
            user_input_lower = user_input.lower()
            today = datetime.now()
            
            print(f"[ğŸ“… ë‚ ì§œ íŒŒì‹±] ì…ë ¥: '{user_input}'")
            
            # ì˜¤ëŠ˜
            if any(keyword in user_input_lower for keyword in ["ì˜¤ëŠ˜", "today"]):
                start_date = today.replace(hour=0, minute=0, second=0, microsecond=0)
                end_date = today.replace(hour=23, minute=59, second=59, microsecond=999999)
                print(f"[ğŸ“… íŒŒì‹± ê²°ê³¼] ì˜¤ëŠ˜: {start_date.date()}")
                return {
                    'type': 'today',
                    'start_date': start_date,
                    'end_date': end_date
                }
            
            # ì–´ì œ
            elif any(keyword in user_input_lower for keyword in ["ì–´ì œ", "yesterday"]):
                yesterday = today - timedelta(days=1)
                start_date = yesterday.replace(hour=0, minute=0, second=0, microsecond=0)
                end_date = yesterday.replace(hour=23, minute=59, second=59, microsecond=999999)
                print(f"[ğŸ“… íŒŒì‹± ê²°ê³¼] ì–´ì œ: {start_date.date()}")
                return {
                    'type': 'yesterday',
                    'start_date': start_date,
                    'end_date': end_date
                }
            
            # ì§€ë‚œì£¼
            elif any(keyword in user_input_lower for keyword in ["ì§€ë‚œì£¼", "last week"]):
                # ì§€ë‚œì£¼ ì›”ìš”ì¼ë¶€í„° ì¼ìš”ì¼ê¹Œì§€
                days_since_monday = today.weekday()
                last_monday = today - timedelta(days=days_since_monday + 7)
                last_sunday = last_monday + timedelta(days=6)
                
                start_date = last_monday.replace(hour=0, minute=0, second=0, microsecond=0)
                end_date = last_sunday.replace(hour=23, minute=59, second=59, microsecond=999999)
                print(f"[ğŸ“… íŒŒì‹± ê²°ê³¼] ì§€ë‚œì£¼: {start_date.date()} ~ {end_date.date()}")
                return {
                    'type': 'last_week',
                    'start_date': start_date,
                    'end_date': end_date
                }
            
            # ì´ë²ˆì£¼
            elif any(keyword in user_input_lower for keyword in ["ì´ë²ˆì£¼", "ì´ë²ˆ ì£¼", "this week"]):
                days_since_monday = today.weekday()
                this_monday = today - timedelta(days=days_since_monday)
                
                start_date = this_monday.replace(hour=0, minute=0, second=0, microsecond=0)
                end_date = today.replace(hour=23, minute=59, second=59, microsecond=999999)
                print(f"[ğŸ“… íŒŒì‹± ê²°ê³¼] ì´ë²ˆì£¼: {start_date.date()} ~ {end_date.date()}")
                return {
                    'type': 'this_week',
                    'start_date': start_date,
                    'end_date': end_date
                }
            
            # ì§€ë‚œë‹¬
            elif any(keyword in user_input_lower for keyword in ["ì§€ë‚œë‹¬", "last month"]):
                # ì§€ë‚œë‹¬ 1ì¼ë¶€í„° ë§ì¼ê¹Œì§€
                first_day_this_month = today.replace(day=1)
                last_day_last_month = first_day_this_month - timedelta(days=1)
                first_day_last_month = last_day_last_month.replace(day=1)
                
                start_date = first_day_last_month.replace(hour=0, minute=0, second=0, microsecond=0)
                end_date = last_day_last_month.replace(hour=23, minute=59, second=59, microsecond=999999)
                print(f"[ğŸ“… íŒŒì‹± ê²°ê³¼] ì§€ë‚œë‹¬: {start_date.date()} ~ {end_date.date()}")
                return {
                    'type': 'last_month',
                    'start_date': start_date,
                    'end_date': end_date
                }
            
            # ì´ë²ˆë‹¬
            elif any(keyword in user_input_lower for keyword in ["ì´ë²ˆë‹¬", "ì´ë²ˆ ë‹¬", "this month"]):
                first_day_this_month = today.replace(day=1)
                
                start_date = first_day_this_month.replace(hour=0, minute=0, second=0, microsecond=0)
                end_date = today.replace(hour=23, minute=59, second=59, microsecond=999999)
                print(f"[ğŸ“… íŒŒì‹± ê²°ê³¼] ì´ë²ˆë‹¬: {start_date.date()} ~ {end_date.date()}")
                return {
                    'type': 'this_month',
                    'start_date': start_date,
                    'end_date': end_date
                }
            
            # ìµœê·¼ Nì¼
            import re
            recent_pattern = re.search(r'ìµœê·¼\s*(\d+)\s*ì¼', user_input_lower)
            if recent_pattern:
                days = int(recent_pattern.group(1))
                start_date = today - timedelta(days=days)
                end_date = today
                print(f"[ğŸ“… íŒŒì‹± ê²°ê³¼] ìµœê·¼ {days}ì¼: {start_date.date()} ~ {end_date.date()}")
                return {
                    'type': f'recent_{days}_days',
                    'start_date': start_date,
                    'end_date': end_date
                }
            
            print(f"[ğŸ“… íŒŒì‹± ê²°ê³¼] ë‚ ì§œ í‚¤ì›Œë“œ ì—†ìŒ")
            return None
            
        except Exception as e:
            print(f"[â—ë‚ ì§œ íŒŒì‹± ì˜¤ë¥˜] {str(e)}")
            return None
    
    def _parse_limit_keywords(self, user_input):
        """ì‚¬ìš©ì ì…ë ¥ì—ì„œ ê°œìˆ˜ ì œí•œ í‚¤ì›Œë“œ íŒŒì‹±"""
        try:
            import re
            
            user_input_lower = user_input.lower()
            
            # "Nê°œë§Œ", "Nê°œ", "Nê°œê¹Œì§€" íŒ¨í„´
            limit_patterns = [
                r'(\d+)\s*ê°œ\s*ë§Œ',
                r'(\d+)\s*ê°œ\s*ê¹Œì§€',
                r'(\d+)\s*ê°œ(?!\s*[ì´ê°€ëŠ”ì„])',  # "ê°œ" ë’¤ì— ì¡°ì‚¬ê°€ ì—†ëŠ” ê²½ìš°
                r'ìµœê·¼\s*(\d+)\s*ê°œ',
                r'ìµœì‹ \s*(\d+)\s*ê°œ',
                r'ì²˜ìŒ\s*(\d+)\s*ê°œ',
                r'ìƒìœ„\s*(\d+)\s*ê°œ'
            ]
            
            for pattern in limit_patterns:
                match = re.search(pattern, user_input_lower)
                if match:
                    limit_count = int(match.group(1))
                    print(f"[ğŸ”¢ ê°œìˆ˜ ì œí•œ íŒŒì‹±] {limit_count}ê°œë¡œ ì œí•œ")
                    return limit_count
            
            print(f"[ğŸ”¢ ê°œìˆ˜ ì œí•œ íŒŒì‹±] ì œí•œ ì—†ìŒ")
            return None
            
        except Exception as e:
            print(f"[â—ê°œìˆ˜ íŒŒì‹± ì˜¤ë¥˜] {str(e)}")
            return None
    
    def _extract_settings_with_keywords(self, user_input):
        """í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ì„¤ì •ê°’ì„ ì¶”ì¶œ"""
        try:
            print(f"[ğŸ” í‚¤ì›Œë“œ ì„¤ì • ì¶”ì¶œ] ì…ë ¥: '{user_input}'")
            
            user_lower = user_input.lower()
            
            # í…Œë§ˆ ì„¤ì • ê°ì§€
            if any(keyword in user_lower for keyword in ['ë‹¤í¬ëª¨ë“œ', 'ë‹¤í¬ ëª¨ë“œ', 'dark', 'ì–´ë‘ìš´']):
                return 'theme', 'dark'
            elif any(keyword in user_lower for keyword in ['ë¼ì´íŠ¸ëª¨ë“œ', 'ë¼ì´íŠ¸ ëª¨ë“œ', 'light', 'ë°ì€', 'ê¸°ë³¸']):
                return 'theme', 'light'
            elif any(keyword in user_lower for keyword in ['ìë™', 'auto', 'ì‹œìŠ¤í…œ']):
                return 'theme', 'auto'
            
            # í°íŠ¸ í¬ê¸° ì„¤ì • ê°ì§€
            if any(keyword in user_lower for keyword in ['í°íŠ¸', 'ê¸€ì', 'í¬ê¸°', 'font', 'size']):
                import re
                # ìˆ«ì ì¶”ì¶œ
                numbers = re.findall(r'\d+', user_input)
                if numbers:
                    size = int(numbers[0])
                    if 10 <= size <= 22:  # ìœ íš¨í•œ í°íŠ¸ í¬ê¸° ë²”ìœ„
                        return 'fontSize', f'{size}px'
            
            # í°íŠ¸ ì¢…ë¥˜ ì„¤ì • ê°ì§€
            font_keywords = ['arial', 'helvetica', 'ë‚˜ëˆ”ê³ ë”•', 'nanumgothic', 'ë§‘ì€ê³ ë”•', 'malgun', 'times', 'ê¶ì„œ']
            for font in font_keywords:
                if font in user_lower:
                    return 'fontFamily', font
            
            # Gmail ê°€ì ¸ì˜¤ê¸° ê°œìˆ˜ ì„¤ì •
            if any(keyword in user_lower for keyword in ['gmail', 'ì§€ë©”ì¼', 'ê°€ì ¸ì˜¤ê¸°', 'ê°œìˆ˜']):
                import re
                numbers = re.findall(r'\d+', user_input)
                if numbers:
                    count = int(numbers[0])
                    if 10 <= count <= 100:  # ìœ íš¨í•œ ë²”ìœ„
                        return 'gmailFetchCount', str(count)
            
            # í˜ì´ì§€ë‹¹ ì•„ì´í…œ ê°œìˆ˜ ì„¤ì •
            if any(keyword in user_lower for keyword in ['í˜ì´ì§€', 'ëª©ë¡', 'ì•„ì´í…œ', 'ê°œìˆ˜', 'ë³´ì—¬', 'í‘œì‹œ']):
                import re
                numbers = re.findall(r'\d+', user_input)
                if numbers:
                    count = int(numbers[0])
                    if 5 <= count <= 50:  # ìœ íš¨í•œ ë²”ìœ„
                        return 'itemsPerPage', str(count)
            
            # ë°œì‹ ì ì´ë¦„ ì„¤ì • - ë” ì •í™•í•œ íŒ¨í„´ ë§¤ì¹­
            sender_keywords = ['ë°œì‹ ì', 'ë°œì‹ ì¥', 'ë³´ë‚¸ì‚¬ëŒ', 'ë³´ë‚¸ì´', 'ë°œì†¡ì', 'ì†¡ì‹ ì', 'sender', 'ë³´ë‚´ëŠ”ì‚¬ëŒ', 'ë³´ë‚´ëŠ”ì´']
            name_keywords = ['ì´ë¦„', 'ëª…', 'ì„±ëª…']
            action_keywords = ['ë°”ê¿”', 'ë³€ê²½', 'ì„¤ì •', 'ìˆ˜ì •', 'ê³ ì³', 'ë°”ê¾¸', 'ë³€ê²½í•´', 'ì„¤ì •í•´']
            
            # ë°œì‹ ì ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
            has_sender = any(keyword in user_lower for keyword in sender_keywords)
            has_name = any(keyword in user_lower for keyword in name_keywords)
            has_action = any(keyword in user_lower for keyword in action_keywords)
            
            # ë°œì‹ ì + ì´ë¦„ ì¡°í•© ë˜ëŠ” ë°œì‹ ì + ì•¡ì…˜ ì¡°í•©ì´ë©´ ë°œì‹ ì ì´ë¦„ ì„¤ì •
            if has_sender and (has_name or has_action):
                print(f"[ğŸ“§ ë°œì‹ ì ì´ë¦„ ì„¤ì • ê°ì§€] ì…ë ¥: '{user_input}'")
                return 'senderName_request', 'need_input'
            
            print(f"[âŒ ì„¤ì • ì¶”ì¶œ ì‹¤íŒ¨] ì¸ì‹í•  ìˆ˜ ì—†ëŠ” ëª…ë ¹: '{user_input}'")
            return None, None
            
        except Exception as e:
            print(f"[â— í‚¤ì›Œë“œ ì„¤ì • ì¶”ì¶œ ì˜¤ë¥˜] {str(e)}")
            return None, None

    def _handle_settings_control(self, user_input, user_email, details):
        """ì„¤ì • ë³€ê²½ ì²˜ë¦¬ (í‚¤ì›Œë“œ ê¸°ë°˜)"""
        try:
            import requests
            
            print(f"[âš™ï¸ ì„¤ì • ë³€ê²½] ì‚¬ìš©ì ì…ë ¥: '{user_input}'")
            print(f"[ğŸ“‹ ì„¸ë¶€ì‚¬í•­] {details}")
            
            
            # 1. í‚¤ì›Œë“œë¡œ ì„¤ì •ê°’ ì¶”ì¶œ
            setting_type, setting_value = self._extract_settings_with_keywords(user_input)
            
            if not setting_type or not setting_value:
                return "â“ ì„¤ì • ë‚´ìš©ì„ íŒŒì•…í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.\n\nì˜ˆ: 'í°íŠ¸ í¬ê¸° 18ë¡œ', 'ë‹¤í¬ëª¨ë“œë¡œ', 'Arial í°íŠ¸ë¡œ'"
            
            # 2. ì¶”ì¶œëœ ì„¤ì •ê°’ìœ¼ë¡œ API í˜¸ì¶œ
            print(f"[ğŸ¯ ì„¤ì • ì‹¤í–‰] {setting_type} â†’ {setting_value}")
            
            # í…Œë§ˆ ì„¤ì •
            if setting_type == "theme":
                response = requests.put(
                    f'http://localhost:5001/api/settings/GENERAL/THEME/appearance',
                    json={
                        'email': user_email,
                        'value': setting_value
                    }
                )
                
                if response.status_code == 200:
                    # ì„¤ì • ë³€ê²½ ì™„ë£Œ ì‹œ ì´ë²¤íŠ¸ ë°œìƒ
                    # ì†Œì¼“ ì„œë²„ê°€ ì—†ìœ¼ë¯€ë¡œ ì´ë²¤íŠ¸ ì „ì†¡ ë¶ˆê°€
                    print(f"[âš ï¸ ì†Œì¼“ ì„œë²„ ì—†ìŒ] ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ë¶ˆê°€ - UI ìƒˆë¡œê³ ì¹¨ í•„ìš”")
                    
                    theme_names = {"dark": "ë‹¤í¬ ëª¨ë“œ", "light": "ë¼ì´íŠ¸ ëª¨ë“œ", "auto": "ìë™ ëª¨ë“œ"}
                    return f"âœ… í…Œë§ˆê°€ {theme_names.get(setting_value, setting_value)}ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ¨"
                else:
                    return "âŒ í…Œë§ˆ ë³€ê²½ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            
            # í°íŠ¸ í¬ê¸° ì„¤ì •
            elif setting_type == "fontSize":
                # "18px" â†’ 18 ì¶”ì¶œ
                import re
                size_match = re.search(r'\d+', setting_value)
                if size_match:
                    size = int(size_match.group())
                    if 10 <= size <= 22:
                        response = requests.put(
                            f'http://localhost:5001/api/settings/GENERAL/WRITE/fontSize',
                            json={
                                'email': user_email,
                                'value': f'{size}px'
                            }
                        )
                        if response.status_code == 200:
                            # ì„¤ì • ë³€ê²½ ì™„ë£Œ ì‹œ ì´ë²¤íŠ¸ ë°œìƒ
                            try:
                                import socketio
                                sio = socketio.SimpleClient()
                                sio.connect('http://localhost:5001')
                                sio.emit('settingsUpdated', {'email': user_email})
                                sio.disconnect()
                            except Exception as e:
                                print(f"[âš ï¸ ì†Œì¼“ ì´ë²¤íŠ¸ ì „ì†¡ ì‹¤íŒ¨] {e}")
                            
                            return f"âœ… í°íŠ¸ í¬ê¸°ê°€ {size}pxë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ”¤"
                        else:
                            return "âŒ í°íŠ¸ í¬ê¸° ë³€ê²½ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                    else:
                        return "âš ï¸ í°íŠ¸ í¬ê¸°ëŠ” 10~22 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤."
                else:
                    return "âŒ ì˜¬ë°”ë¥¸ í°íŠ¸ í¬ê¸° í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤."
            
            # í°íŠ¸ ì¢…ë¥˜ ì„¤ì •  
            elif setting_type == "fontFamily":
                font_map = {
                    "Arial": "Arial",
                    "ë§‘ì€ê³ ë”•": "ë§‘ì€ ê³ ë”•", 
                    "ë‹ì›€": "ë‹ì›€",
                    "êµ´ë¦¼": "êµ´ë¦¼",
                    "ë°”íƒ•": "ë°”íƒ•",
                    "ê¶ì„œ": "ê¶ì„œ",
                    "Times": "Times New Roman",
                    "Helvetica": "Helvetica",
                    "Verdana": "Verdana", 
                    "Georgia": "Georgia",
                    "Courier": "Courier New",
                    "ì‹œìŠ¤í…œê¸°ë³¸": "system"
                }
                
                font_family = font_map.get(setting_value, setting_value)
                response = requests.put(
                    f'http://localhost:5001/api/settings/GENERAL/WRITE/fontFamily',
                    json={
                        'email': user_email,
                        'value': font_family
                    }
                )
                if response.status_code == 200:
                    # ì„¤ì • ë³€ê²½ ì™„ë£Œ ì‹œ ì´ë²¤íŠ¸ ë°œìƒ
                    # ì†Œì¼“ ì„œë²„ê°€ ì—†ìœ¼ë¯€ë¡œ ì´ë²¤íŠ¸ ì „ì†¡ ë¶ˆê°€
                    print(f"[âš ï¸ ì†Œì¼“ ì„œë²„ ì—†ìŒ] ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ë¶ˆê°€ - UI ìƒˆë¡œê³ ì¹¨ í•„ìš”")
                    
                    return f"âœ… í°íŠ¸ê°€ {font_family}ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ“"
                else:
                    return "âŒ í°íŠ¸ ë³€ê²½ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            
            # Gmail ê°€ì ¸ì˜¤ê¸° ê°œìˆ˜
            elif setting_type == "gmailFetchCount":
                count = int(setting_value)
                if 3 <= count <= 100:
                    response = requests.put(
                        f'http://localhost:5001/api/settings/GENERAL/READ/gmailFetchCount',
                        json={
                            'email': user_email,
                            'value': count
                        }
                    )
                    if response.status_code == 200:
                        # ì„¤ì • ë³€ê²½ ì™„ë£Œ ì‹œ ì´ë²¤íŠ¸ ë°œìƒ
                        try:
                            import socketio
                            sio = socketio.SimpleClient()
                            sio.connect('http://localhost:5001')
                            sio.emit('settingsUpdated', {'email': user_email})
                            sio.disconnect()
                        except Exception as e:
                            print(f"[âš ï¸ ì†Œì¼“ ì´ë²¤íŠ¸ ì „ì†¡ ì‹¤íŒ¨] {e}")
                        
                        return f"âœ… Gmail ê°€ì ¸ì˜¤ê¸° ê°œìˆ˜ê°€ {count}ê°œë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ“§"
                    else:
                        return "âŒ Gmail ê°œìˆ˜ ì„¤ì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                else:
                    return "âš ï¸ Gmail ê°œìˆ˜ëŠ” 3~100 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤."
            
            # í˜ì´ì§€ë‹¹ í‘œì‹œ ê°œìˆ˜
            elif setting_type == "itemsPerPage":
                size = int(setting_value)
                if 3 <= size <= 50:
                    response = requests.put(
                        f'http://localhost:5001/api/settings/GENERAL/READ/itemsPerPage',
                        json={
                            'email': user_email,
                            'value': size
                        }
                    )
                    if response.status_code == 200:
                        # ì„¤ì • ë³€ê²½ ì™„ë£Œ ì‹œ ì´ë²¤íŠ¸ ë°œìƒ
                        try:
                            import socketio
                            sio = socketio.SimpleClient()
                            sio.connect('http://localhost:5001')
                            sio.emit('settingsUpdated', {'email': user_email})
                            sio.disconnect()
                        except Exception as e:
                            print(f"[âš ï¸ ì†Œì¼“ ì´ë²¤íŠ¸ ì „ì†¡ ì‹¤íŒ¨] {e}")
                        
                        return f"âœ… í˜ì´ì§€ë‹¹ í‘œì‹œ ê°œìˆ˜ê°€ {size}ê°œë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ“„"
                    else:
                        return "âŒ í˜ì´ì§€ ì„¤ì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                else:
                    return "âš ï¸ í˜ì´ì§€ë‹¹ ê°œìˆ˜ëŠ” 3~50 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤."
            
            # ë°œì‹ ì ì´ë¦„ ì…ë ¥ ìš”ì²­
            elif setting_type == "senderName_request":
                # ì„ì‹œ íŒŒì¼ì— ìš”ì²­ ìƒíƒœ ì €ì¥
                try:
                    import os
                    temp_dir = "user_sessions"
                    os.makedirs(temp_dir, exist_ok=True)
                    temp_file = os.path.join(temp_dir, f"{user_email}_awaiting_name.txt")
                    with open(temp_file, 'w', encoding='utf-8') as f:
                        f.write("waiting")
                    print(f"[ğŸ’¾ ìƒíƒœ ì €ì¥] ë°œì‹ ì ì´ë¦„ ì…ë ¥ ëŒ€ê¸° ìƒíƒœ ì €ì¥")
                except Exception as e:
                    print(f"[âš ï¸ ìƒíƒœ ì €ì¥ ì‹¤íŒ¨] {e}")
                
                return """ğŸ“§ **ë°œì‹ ì ì´ë¦„ ì„¤ì •**

ì›í•˜ëŠ” ë°œì‹ ì ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.
ì˜ˆ: ìµœìˆ˜ìš´, ê¹€ì² ìˆ˜, John Smith"""

            # ì‹¤ì œ ë°œì‹ ì ì´ë¦„ ì„¤ì •
            elif setting_type == "senderName":
                print(f"[ğŸ”§ API í˜¸ì¶œ] PUT /api/settings/GENERAL/WRITE/senderName")
                print(f"[ğŸ“¤ ìš”ì²­ ë°ì´í„°] email: {user_email}, value: {setting_value}")
                
                response = requests.put(
                    f'http://localhost:5001/api/settings/GENERAL/WRITE/senderName',
                    json={
                        'email': user_email,
                        'value': setting_value
                    }
                )
                
                print(f"[ğŸ“¥ ì‘ë‹µ ìƒíƒœ] {response.status_code}")
                if response.status_code == 200:
                    response_data = response.json()
                    print(f"[ğŸ“¥ ì‘ë‹µ ë°ì´í„°] {response_data}")
                    # ì†Œì¼“ ì„œë²„ê°€ ì—†ìœ¼ë¯€ë¡œ ì´ë²¤íŠ¸ ì „ì†¡ ë¶ˆê°€
                    print(f"[âš ï¸ ì†Œì¼“ ì„œë²„ ì—†ìŒ] Flask-SocketIOê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ë¶ˆê°€")
                    print(f"[ğŸ’¡ í•´ê²°ë°©ë²•] ì„¤ì • UI í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ë©´ ë³€ê²½ì‚¬í•­ì´ ë°˜ì˜ë©ë‹ˆë‹¤.")
                    
                    # DB ê°’ í™•ì¸ (ê²€ì¦ìš©)
                    print(f"[ğŸ” DB ê²€ì¦ ì‹œì‘] ì„¤ì •ì´ ì‹¤ì œë¡œ ì €ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸...")
                    try:
                        # 1ì´ˆ ëŒ€ê¸° (DB ì»¤ë°‹ ì™„ë£Œ ëŒ€ê¸°)
                        import time
                        time.sleep(1)
                        
                        # ì „ì²´ WRITE ì„¹ì…˜ ì¡°íšŒ
                        verify_response = requests.get(
                            f'http://localhost:5001/api/settings/GENERAL/WRITE',
                            params={'email': user_email}
                        )
                        print(f"[ğŸ” DB ê²€ì¦] GET ì‘ë‹µ ì½”ë“œ: {verify_response.status_code}")
                        
                        if verify_response.status_code == 200:
                            verify_data = verify_response.json()
                            print(f"[ğŸ” DB ê²€ì¦] ì „ì²´ ì‘ë‹µ: {verify_data}")
                            
                            settings_data = verify_data.get('settings', {})
                            actual_value = settings_data.get('senderName', 'N/A')
                            
                            print(f"[ğŸ“Š DB ê²€ì¦ ê²°ê³¼]")
                            print(f"  - ìš”ì²­í•œ ê°’: '{setting_value}'")
                            print(f"  - ì €ì¥ëœ ê°’: '{actual_value}'")
                            print(f"  - ì „ì²´ WRITE ì„¤ì •: {settings_data}")
                            
                            if actual_value != setting_value:
                                print(f"[âŒ DB ì˜¤ë¥˜] ì„¤ì •ê°’ ë¶ˆì¼ì¹˜! DBì— ì œëŒ€ë¡œ ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                                print(f"[ğŸ’¡ ì›ì¸] DB ì»¤ë°‹ ì‹¤íŒ¨ ë˜ëŠ” ì„¸ì…˜ ë¶ˆì¼ì¹˜ ê°€ëŠ¥ì„±")
                            else:
                                print(f"[âœ… DB ì„±ê³µ] ì„¤ì •ê°’ì´ ì •ìƒì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                print(f"[ğŸ’¡ UI ë¬¸ì œ] DBëŠ” ì •ìƒì´ë¯€ë¡œ UI ìƒˆë¡œê³ ì¹¨ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                        else:
                            print(f"[âŒ DB ê²€ì¦ ì‹¤íŒ¨] API ì‘ë‹µ ì˜¤ë¥˜: {verify_response.text}")
                    except Exception as e:
                        print(f"[âŒ DB ê²€ì¦ ì‹¤íŒ¨] ì˜ˆì™¸ ë°œìƒ: {e}")
                    
                    return f"âœ… ë³´ë‚´ëŠ” ì´ë¦„ì´ '{setting_value}'ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‘¤"
                else:
                    response_data = response.json() if response.content else {}
                    error_msg = response_data.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')
                    return f"âŒ ë³´ë‚´ëŠ” ì´ë¦„ ì„¤ì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜: {error_msg}"
                    
            else:
                return f"â“ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì„¤ì • íƒ€ì…ì…ë‹ˆë‹¤: {setting_type}"
                
        except Exception as e:
            print(f"[â—ì„¤ì • ë³€ê²½ ì˜¤ë¥˜] {str(e)}")
            return f"âŒ ì„¤ì • ë³€ê²½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def _parse_mail_type_keywords(self, user_input):
        """ì‚¬ìš©ì ì…ë ¥ì—ì„œ ë©”ì¼ íƒ€ì… í‚¤ì›Œë“œ íŒŒì‹±"""
        try:
            user_input_lower = user_input.lower()
            
            # ë°›ì€ë©”ì¼ í‚¤ì›Œë“œ
            if any(keyword in user_input_lower for keyword in ["ë°›ì€ ë©”ì¼", "ë°›ì€ë©”ì¼", "ìˆ˜ì‹ ", "inbox", "ë°›ì€"]):
                print(f"[ğŸ“§ íƒ€ì… íŒŒì‹±] ë°›ì€ë©”ì¼ë§Œ ê²€ìƒ‰")
                return 'inbox'
            
            # ë³´ë‚¸ë©”ì¼ í‚¤ì›Œë“œ  
            elif any(keyword in user_input_lower for keyword in ["ë³´ë‚¸ ë©”ì¼", "ë³´ë‚¸ë©”ì¼", "ë°œì‹ ", "sent", "ë³´ë‚¸"]):
                print(f"[ğŸ“§ íƒ€ì… íŒŒì‹±] ë³´ë‚¸ë©”ì¼ë§Œ ê²€ìƒ‰")
                return 'sent'
            
            print(f"[ğŸ“§ íƒ€ì… íŒŒì‹±] ëª¨ë“  íƒ€ì…")
            return None
            
        except Exception as e:
            print(f"[â—íƒ€ì… íŒŒì‹± ì˜¤ë¥˜] {str(e)}")
            return None
    
    def _try_learned_pattern(self, user_email, user_input, app_password):
        """í•™ìŠµëœ íŒ¨í„´ì—ì„œ ë§¤ì¹­ ì‹œë„"""
        try:
            from models.tables import Chatbot
            
            # DBì—ì„œ ì‚¬ìš©ìì˜ í•™ìŠµëœ ëª…ë ¹ì–´ë“¤ ì¡°íšŒ
            print(f"[ğŸ” DB ì¡°íšŒ] ì‚¬ìš©ì '{user_email}'ì˜ í•™ìŠµëœ ëª…ë ¹ì–´ ê²€ìƒ‰ ì¤‘...")
            learned_commands = Chatbot.query.filter_by(user_email=user_email).all()
            
            print(f"[ğŸ“Š DB ê²°ê³¼] í•™ìŠµëœ ëª…ë ¹ì–´ {len(learned_commands)}ê°œ ë°œê²¬")
            if not learned_commands:
                print(f"[âŒ í•™ìŠµ ë°ì´í„° ì—†ìŒ] ì²˜ìŒ ì‚¬ìš©í•˜ëŠ” ëª…ë ¹ì–´ì…ë‹ˆë‹¤")
                return None
            
            # í•™ìŠµëœ ëª…ë ¹ì–´ ëª©ë¡ ì¶œë ¥
            for i, cmd in enumerate(learned_commands, 1):
                print(f"[ğŸ“ í•™ìŠµ #{i}] '{cmd.command}' -> {cmd.intent} (ì‚¬ìš©íšŸìˆ˜: {cmd.use_count})")
            
            user_input_lower = user_input.lower()
            best_match = None
            best_similarity = 0.0
            
            print(f"[ğŸ”„ ìœ ì‚¬ë„ ê³„ì‚°] ì…ë ¥ ëª…ë ¹ì–´ì™€ ê° í•™ìŠµ ë°ì´í„° ë¹„êµ ì¤‘...")
            
            # ê° í•™ìŠµëœ ëª…ë ¹ì–´ì™€ ìœ ì‚¬ë„ ë¹„êµ
            for i, learned in enumerate(learned_commands, 1):
                similarity = self._calculate_similarity_enhanced(user_input_lower, learned.command.lower())
                print(f"[ğŸ“ ìœ ì‚¬ë„ #{i}] '{learned.command}' vs '{user_input}' = {similarity:.3f} ({'âœ… ì„ê³„ê°’ í†µê³¼' if similarity > 0.75 else 'âŒ ì„ê³„ê°’ ë¯¸ë‹¬'})")
                
                if similarity > best_similarity and similarity > 0.75:  # 75% ì´ìƒ
                    best_match = learned
                    best_similarity = similarity
            
            if best_match:
                print(f"[ğŸ¯ ìµœê³  ë§¤ì¹­] '{best_match.command}' (ìœ ì‚¬ë„: {best_similarity:.3f})")
                print(f"[ğŸ“ˆ ì‚¬ìš© í†µê³„] ê¸°ì¡´ {best_match.use_count}íšŒ â†’ {best_match.use_count + 1}íšŒë¡œ ì¦ê°€")
                
                # ì‚¬ìš© íšŸìˆ˜ ì¦ê°€
                best_match.use_count += 1
                
                from models.db import db
                db.session.commit()
                
                # í•™ìŠµëœ intentë¡œ ì‹¤í–‰ (ì›ë³¸ ì…ë ¥ í¬í•¨)
                print(f"[ğŸš€ í•™ìŠµ íŒ¨í„´ ì‹¤í–‰] intent='{best_match.intent}', keywords={best_match.get_keywords_dict()}")
                return self._execute_learned_intent(best_match.intent, best_match.get_keywords_dict(), user_email, app_password, original_input=user_input)
            else:
                print(f"[âŒ ë§¤ì¹­ ì‹¤íŒ¨] ìœ ì‚¬ë„ 75% ì´ìƒì¸ í•™ìŠµ ë°ì´í„° ì—†ìŒ (ìµœê³ : {best_similarity:.3f})")
                
        except Exception as e:
            print(f"[â— í•™ìŠµ íŒ¨í„´ ë§¤ì¹­ ì˜¤ë¥˜] {str(e)}")
            
        return None
    
    def _calculate_similarity_enhanced(self, cmd1, cmd2):
        """í–¥ìƒëœ ìœ ì‚¬ë„ ê³„ì‚° (í‚¤ì›Œë“œ ê¸°ë°˜)"""
        
        # í•µì‹¬ í‚¤ì›Œë“œë“¤ ì •ì˜ (8ê°œ íƒ€ì… ê¸°ë°˜)
        key_words = [
            # sender
            "êµìˆ˜ë‹˜", "íšŒì‚¬", "í•™ê³¼", "ì„ ìƒë‹˜", "êµì§ì›", "naver", "google", "microsoft",
            # date  
            "ì˜¤ëŠ˜", "ì–´ì œ", "ì´ë²ˆì£¼", "ì§€ë‚œì£¼", "ì´ë²ˆë‹¬", "ì§€ë‚œë‹¬", "ìµœê·¼",
            # tag
            "ì¤‘ìš”", "ìŠ¤íŒ¸", "ë³´ì•ˆ", "ëŒ€í•™êµ",
            # attachment
            "ì²¨ë¶€íŒŒì¼", "ì´ë¯¸ì§€", "pdf", "ë¬¸ì„œ", "íŒŒì¼", "ì‚¬ì§„",
            # action
            "ê²€ìƒ‰", "ë³´ì—¬ì¤˜", "ì°¾ì•„ì¤˜", "ì‘ì„±", "ë‹µì¥", "ì‚­ì œ", "ìš”ì•½", "ì¨ì¤˜",
            # content
            "ê³¼ì œ", "íšŒì˜", "ê³µì§€", "ì˜ìˆ˜ì¦", "ë¹„ë°€ë²ˆí˜¸", "ë¡œê·¸ì¸", "ì•Œë¦¼", "ë©”ì¼", "ì´ë©”ì¼",
            # settings (ìƒˆë¡œ ì¶”ê°€)
            "í°íŠ¸", "ê¸€ê¼´", "í¬ê¸°", "ì„¤ì •", "ë°”ê¿”", "ë°”ê¿”ì¤˜", "ë³€ê²½", "ìˆ˜ì •", "ì¡°ì ˆ", "ì ìš©",
            "í…Œë§ˆ", "ë‹¤í¬ëª¨ë“œ", "ë¼ì´íŠ¸ëª¨ë“œ", "Gmail", "ê°œìˆ˜", "í˜ì´ì§€"
        ]
        
        common_keywords = 0
        total_keywords = 0
        
        for keyword in key_words:
            in_cmd1 = keyword in cmd1
            in_cmd2 = keyword in cmd2
            
            if in_cmd1 or in_cmd2:
                total_keywords += 1
                if in_cmd1 and in_cmd2:
                    common_keywords += 1
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ìœ ì‚¬ë„
        keyword_similarity = common_keywords / total_keywords if total_keywords > 0 else 0
        
        # ê¸°ì¡´ ë‹¨ì–´ ê¸°ë°˜ ìœ ì‚¬ë„ë„ ê°™ì´ ê³ ë ¤
        word_similarity = self._calculate_word_similarity(cmd1, cmd2)
        
        # ë‘ ìœ ì‚¬ë„ì˜ í‰ê·  (í‚¤ì›Œë“œ ê¸°ë°˜ì„ ë” ì¤‘ìš”í•˜ê²Œ)
        return keyword_similarity * 0.7 + word_similarity * 0.3
    
    def _calculate_word_similarity(self, cmd1, cmd2):
        """ë‹¨ì–´ ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°"""
        words1 = set(cmd1.split())
        words2 = set(cmd2.split())
        
        if not words1 and not words2:
            return 1.0
        
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        
        return len(intersection) / len(union) if union else 0.0
    
    def _execute_learned_intent(self, intent, keywords, user_email, app_password, original_input=None):
        """í•™ìŠµëœ intent ì‹¤í–‰"""
        
        print(f"[ğŸ¯ í•™ìŠµëœ Intent ì‹¤í–‰ ì‹œì‘] intent='{intent}'")
        print(f"[ğŸ·ï¸ ì‚¬ìš© í‚¤ì›Œë“œ] {keywords}")
        print(f"[ğŸ“ ì›ë³¸ ì…ë ¥] '{original_input}'")
        
        # ê¸°ì¡´ í•¸ë“¤ëŸ¬ë“¤ì„ ê·¸ëŒ€ë¡œ í™œìš©
        if intent == "person_search":
            print(f"[ğŸ‘¤ ì‚¬ëŒë³„ ê²€ìƒ‰ ì‹¤í–‰] í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ ëŒ€ìƒ ì¶”ì¶œ ì¤‘...")
            # keywordsì—ì„œ ê²€ìƒ‰ ëŒ€ìƒ ì¶”ì¶œ
            search_target = keywords.get('sender', '') or keywords.get('content', '')
            print(f"[ğŸ¯ ê²€ìƒ‰ ëŒ€ìƒ] '{search_target}'")
            if search_target:
                # ê¸°ì¡´ í•¨ìˆ˜ í™œìš©í•˜ë˜, ê²€ìƒ‰ ëŒ€ìƒì„ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬
                user_input_reconstructed = f"{search_target} ë©”ì¼"
                print(f"[ğŸ”„ ëª…ë ¹ì–´ ì¬êµ¬ì„±] '{user_input_reconstructed}'")
                response = self._handle_person_search(user_input_reconstructed, user_email, app_password)
            else:
                print(f"[âš ï¸ ê²€ìƒ‰ ëŒ€ìƒ ì—†ìŒ] ê¸°ë³¸ ì‚¬ëŒ ê²€ìƒ‰ ì‹¤í–‰")
                response = self._handle_person_search("", user_email, app_password)
                
        elif intent == "email_search":
            print(f"[ğŸ” ì¼ë°˜ ê²€ìƒ‰ ì‹¤í–‰] í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ì–´ ì¶”ì¶œ ì¤‘...")
            # ì¼ë°˜ ê²€ìƒ‰
            search_keyword = keywords.get('content', '') or keywords.get('sender', '') or keywords.get('tag', '')
            print(f"[ğŸ¯ ê²€ìƒ‰ í‚¤ì›Œë“œ] '{search_keyword}'")
            if search_keyword:
                user_input_reconstructed = f"{search_keyword} ê²€ìƒ‰"
                print(f"[ğŸ”„ ëª…ë ¹ì–´ ì¬êµ¬ì„±] '{user_input_reconstructed}'")
                response = self._handle_general_search(user_input_reconstructed, user_email, app_password)
            else:
                print(f"[âš ï¸ ê²€ìƒ‰ í‚¤ì›Œë“œ ì—†ìŒ] ê¸°ë³¸ ê²€ìƒ‰ ì‹¤í–‰")
                response = self._handle_general_search("", user_email, app_password)
                
        elif intent == "grammar_correction":
            print(f"[ğŸ“ ë¬¸ë²• êµì • ì‹¤í–‰] ê¸°ë³¸ ì‘ë‹µ ì œê³µ")
            # ë¬¸ë²• êµì • - ì›ë³¸ ëª…ë ¹ì–´ í•„ìš”í•˜ë¯€ë¡œ ê¸°ë³¸ ì‘ë‹µ
            response = self._handle_grammar_correction("")
            
        elif intent == "image_generation":
            print(f"[ğŸ¨ ì´ë¯¸ì§€ ìƒì„± ì‹¤í–‰] ê¸°ë³¸ ì‘ë‹µ ì œê³µ")
            response = self._handle_image_generation("")
            
        elif intent == "email_statistics":
            print(f"[ğŸ“Š í†µê³„ ì‹¤í–‰] í‚¤ì›Œë“œ ê¸°ë°˜ í†µê³„ ìƒì„±")
            # í‚¤ì›Œë“œì—ì„œ ë‚ ì§œ ì •ë³´ ì¶”ì¶œí•˜ì—¬ í†µê³„ ìƒì„±
            date_keyword = keywords.get('date', '')
            if date_keyword:
                reconstructed_input = f"{date_keyword} ë©”ì¼ ëª‡ ê°œ"
                response = self._handle_email_statistics(reconstructed_input, user_email, app_password)
            else:
                response = self._handle_email_statistics("ì „ì²´ í†µê³„", user_email, app_password)
            
        elif intent == "settings_control":
            print(f"[âš™ï¸ ì„¤ì • ë³€ê²½ ì‹¤í–‰] ì›ë³¸ ëª…ë ¹ì–´ ì‚¬ìš©")
            # ì›ë³¸ ì…ë ¥ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì¬êµ¬ì„± í•˜ì§€ ì•ŠìŒ)
            if original_input:
                response = self._handle_settings_control(original_input, user_email, "")
            else:
                # ì›ë³¸ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ë©”ì‹œì§€
                response = "ì„¤ì • ë³€ê²½ ëª…ë ¹ì„ ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”."
            
        else:
            print(f"[âŒ ì•Œ ìˆ˜ ì—†ëŠ” Intent] '{intent}' ì²˜ë¦¬ ë¶ˆê°€")
            response = "í•™ìŠµëœ íŒ¨í„´ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        print(f"[âœ… í•™ìŠµ íŒ¨í„´ ì‹¤í–‰ ì™„ë£Œ] ì‘ë‹µ ìƒì„±ë¨")
        
        return {
            "response": response,
            "action": intent,
            "confidence": 1.0,  # í•™ìŠµëœ íŒ¨í„´ì€ ë†’ì€ ì‹ ë¢°ë„
            "detected_intent": intent,
            "detection_method": "learned_pattern"
        }
    
    def _auto_save_learned_command(self, user_email, command, intent_result, response):
        """Qwen ë¶„ì„ ê²°ê³¼ë¥¼ ìë™ìœ¼ë¡œ í•™ìŠµ ë°ì´í„°ë¡œ ì €ì¥"""
        try:
            from models.tables import Chatbot
            from models.db import db
            import json
            
            print(f"[ğŸ’¾ ìë™ ì €ì¥] ëª…ë ¹ì–´: '{command}'")
            print(f"[ğŸ’¾ ìë™ ì €ì¥] ì˜ë„: {intent_result['action']} (ì‹ ë¢°ë„: {intent_result['confidence']:.3f})")
            
            # ê¸°ì¡´ì— ë™ì¼í•œ ëª…ë ¹ì–´ê°€ ìˆëŠ”ì§€ í™•ì¸
            existing = Chatbot.query.filter_by(
                user_email=user_email,
                command=command
            ).first()
            
            if existing:
                print(f"[âš ï¸ ìë™ ì €ì¥] ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ëª…ë ¹ì–´ - ì—…ë°ì´íŠ¸")
                existing.intent = intent_result['action']
                existing.use_count += 1
                existing.keywords = json.dumps(self._extract_keywords_from_command(command), ensure_ascii=False)
                # response í•„ë“œëŠ” Chatbot ëª¨ë¸ì— ì—†ìœ¼ë¯€ë¡œ ì œê±°
            else:
                print(f"[âœ… ìë™ ì €ì¥] ìƒˆë¡œìš´ ëª…ë ¹ì–´ - ì¶”ê°€")
                new_command = Chatbot(
                    user_email=user_email,
                    command=command,
                    intent=intent_result['action'],
                    keywords=json.dumps(self._extract_keywords_from_command(command), ensure_ascii=False),
                    use_count=1
                )
                db.session.add(new_command)
            
            db.session.commit()
            print(f"[âœ… ìë™ ì €ì¥] DB ì €ì¥ ì™„ë£Œ")
            
        except Exception as e:
            print(f"[â— ìë™ ì €ì¥ ì˜¤ë¥˜] {str(e)}")
            try:
                db.session.rollback()
            except:
                pass

    def _save_learned_command(self, user_email, command, intent, response):
        """AIë¡œ ì²˜ë¦¬í•œ ê²°ê³¼ë¥¼ í•™ìŠµ ë°ì´í„°ë¡œ ì €ì¥"""
        try:
            from models.tables import Chatbot
            from models.db import db
            import json
            
            print(f"[ğŸ” í‚¤ì›Œë“œ ì¶”ì¶œ] ëª…ë ¹ì–´ì—ì„œ 6ê°œ íƒ€ì… í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘...")
            # í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = self._extract_keywords_from_command(command)
            print(f"[ğŸ“ ì¶”ì¶œëœ í‚¤ì›Œë“œ] {keywords}")
            
            print(f"[ğŸ” ì¤‘ë³µ ê²€ì‚¬] ê¸°ì¡´ í•™ìŠµ ë°ì´í„° í™•ì¸ ì¤‘...")
            # ì´ë¯¸ ê°™ì€ ëª…ë ¹ì–´ê°€ ìˆëŠ”ì§€ í™•ì¸ (ì¤‘ë³µ ë°©ì§€)
            existing = Chatbot.query.filter_by(
                user_email=user_email,
                command=command
            ).first()
            
            if existing:
                # ê¸°ì¡´ ëª…ë ¹ì–´ì˜ ì‚¬ìš© íšŸìˆ˜ë§Œ ì¦ê°€
                print(f"[ğŸ”„ ì¤‘ë³µ ë°ì´í„° ë°œê²¬] ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸ ì§„í–‰")
                print(f"[ğŸ“Š ì‚¬ìš© íšŸìˆ˜] {existing.use_count} â†’ {existing.use_count + 1}")
                existing.use_count += 1
                print(f"[âœ… ê¸°ì¡´ í•™ìŠµ ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ]")
            else:
                # ìƒˆë¡œìš´ í•™ìŠµ ë°ì´í„° ì €ì¥
                print(f"[ğŸ’¾ ì‹ ê·œ í•™ìŠµ ë°ì´í„°] ìƒˆë¡œìš´ íŒ¨í„´ìœ¼ë¡œ ì €ì¥ ì§„í–‰")
                learned_cmd = Chatbot(
                    user_email=user_email,
                    command=command,
                    intent=intent
                )
                learned_cmd.set_keywords_dict(keywords)
                
                db.session.add(learned_cmd)
                print(f"[âœ¨ ìƒˆ í•™ìŠµ íŒ¨í„´ ì €ì¥] ëª…ë ¹ì–´: '{command}'")
                print(f"[ğŸ¯ ì €ì¥ëœ Intent] {intent}")
                print(f"[ğŸ·ï¸ ì €ì¥ëœ í‚¤ì›Œë“œ] {keywords}")
                print(f"[ğŸš€ ë‹¤ìŒë¶€í„° ê³ ì† ì²˜ë¦¬] ë™ì¼/ìœ ì‚¬ ëª…ë ¹ì–´ëŠ” 0.05ì´ˆ ë‚´ ì²˜ë¦¬ë©ë‹ˆë‹¤!")
            
            db.session.commit()
            print(f"[ğŸ’¾ DB ì €ì¥ ì™„ë£Œ] í•™ìŠµ ì‹œìŠ¤í…œì´ ë” ë˜‘ë˜‘í•´ì¡ŒìŠµë‹ˆë‹¤!")
            
        except Exception as e:
            print(f"[â— í•™ìŠµ ì €ì¥ ì˜¤ë¥˜] {str(e)}")
    
    def _extract_keywords_from_command(self, command):
        """ëª…ë ¹ì–´ì—ì„œ 6ê°œ íƒ€ì… í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords = {}
        command_lower = command.lower()
        
        # 7ê°œ í‚¤ì›Œë“œ íƒ€ì…ë³„ ê²€ì‚¬
        keyword_types = {
            'sender': ['êµìˆ˜ë‹˜', 'íšŒì‚¬', 'í•™ê³¼', 'naver', 'google', 'microsoft', 'ì„ ìƒë‹˜', 'êµì§ì›'],
            'date': ['ì˜¤ëŠ˜', 'ì–´ì œ', 'ì´ë²ˆì£¼', 'ì§€ë‚œì£¼', 'ì´ë²ˆë‹¬', 'ì§€ë‚œë‹¬', 'ìµœê·¼'],
            'tag': ['ì¤‘ìš”ë©”ì¼', 'ìŠ¤íŒ¸', 'ë³´ì•ˆê²½ê³ ', 'íšŒì‚¬', 'ëŒ€í•™êµ', 'ì¤‘ìš”', 'ë³´ì•ˆ', 'ë°›ì€ë©”ì¼', 'ë³´ë‚¸ë©”ì¼', 'ë°›ì€', 'ë³´ë‚¸'],
            'attachment': ['ì²¨ë¶€íŒŒì¼', 'ì´ë¯¸ì§€', 'pdf', 'ë¬¸ì„œ', 'íŒŒì¼', 'ì‚¬ì§„', 'ë™ì˜ìƒ'],
            'action': ['ê²€ìƒ‰', 'ë³´ì—¬ì¤˜', 'ì°¾ì•„ì¤˜', 'ì‘ì„±', 'ë‹µì¥', 'ì‚­ì œ', 'ìš”ì•½', 'ì¨ì¤˜', 'ëª‡ê°œ', 'ê°œìˆ˜', 'í†µê³„', 'ê°œë§Œ', 'ê°œê¹Œì§€', 'ì„¤ì •', 'ë³€ê²½', 'ë°”ê¿”'],
            'content': ['ê³¼ì œ', 'íšŒì˜', 'ê³µì§€', 'ì˜ìˆ˜ì¦', 'ë¹„ë°€ë²ˆí˜¸', 'ë¡œê·¸ì¸', 'ì•Œë¦¼', 'ë©”ì¼', 'ì´ë©”ì¼', 'í”„ë¡œì íŠ¸', 'ë³´ê³ ì„œ'],
            'setting': ['ë‹¤í¬ëª¨ë“œ', 'ë¼ì´íŠ¸ëª¨ë“œ', 'í…Œë§ˆ', 'í°íŠ¸', 'í¬ê¸°', 'gmail', 'í˜ì´ì§€', 'í‘œì‹œ', 'ë³´ë‚´ëŠ”', 'ì´ë¦„']
        }
        
        for keyword_type, keyword_list in keyword_types.items():
            for keyword in keyword_list:
                if keyword in command_lower:
                    keywords[keyword_type] = keyword
                    break
        
        return keywords
    
